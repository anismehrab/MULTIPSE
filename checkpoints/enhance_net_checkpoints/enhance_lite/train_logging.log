
22-01-06 18:42:32.857 : #################### Trainning Resumed ####################
22-01-06 18:42:33.346 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-06 18:42:43.348 : ===>Input:[4,3,248,216] output:[4,3,992,864]
22-01-06 18:42:43.421 :        DEVICE ID : cuda
22-01-06 18:42:46.580 : L1 loss function
22-01-06 18:42:46.581 : ===> TrainEpoch =0  lr = 0.0001
22-01-06 19:22:33.713 : ===> Epoch[0]: Loss_l1: 0.06139  Duration: 39.785100 min
22-01-06 19:33:24.674 : ===> Valid. psnr: 25.2718, ssim: 0.6537, loss: 0.0410
22-01-06 19:33:24.777 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_0.pth
22-01-06 19:33:24.777 : 


2

22-01-07 11:18:52.073 : #################### Trainning Resumed ####################
22-01-07 11:18:52.322 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 11:18:57.113 : ===>Input:[4,3,148,160] output:[4,3,592,640]
22-01-07 11:18:57.182 :        DEVICE ID : cuda
22-01-07 11:19:01.148 : L1 loss function
22-01-07 11:19:01.200 : ===> TrainEpoch =1  lr = 0.0001
22-01-07 12:02:27.284 : ===> Epoch[1]: Loss_l1: 0.04148  Duration: 43.434921 min
22-01-07 12:13:14.568 : ===> Valid. psnr: 26.2269, ssim: 0.6808, loss: 0.0371
22-01-07 12:13:14.780 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_1.pth
22-01-07 12:13:14.780 : 

22-01-07 12:13:14.781 : ===> TrainEpoch =2  lr = 0.0001
22-01-07 14:36:36.357 : 

22-01-07 14:36:36.357 : #################### Trainning Resumed ####################
22-01-07 14:36:36.596 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:36:40.232 : ===>Input:[4,3,168,164] output:[4,3,672,656]
22-01-07 14:37:05.473 : 

22-01-07 14:37:05.473 : #################### Trainning Resumed ####################
22-01-07 14:37:05.550 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:37:08.762 : ===>Input:[4,3,152,256] output:[4,3,608,1024]
22-01-07 14:43:25.075 : 

22-01-07 14:43:25.075 : #################### Trainning Resumed ####################
22-01-07 14:43:25.131 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:43:30.601 : ===>Input:[4,3,256,208] output:[4,3,1024,832]
22-01-07 14:50:30.192 : 

22-01-07 14:50:30.192 : #################### Trainning Resumed ####################
22-01-07 14:50:30.297 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:50:35.688 : ===>Input:[4,3,172,224] output:[4,3,688,896]
22-01-07 14:51:51.247 : 

22-01-07 14:51:51.247 : #################### Trainning Resumed ####################
22-01-07 14:51:51.302 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:51:54.234 : ===>Input:[4,3,188,128] output:[4,3,752,512]
22-01-07 14:54:28.120 : 

22-01-07 14:54:28.120 : #################### Trainning Resumed ####################
22-01-07 14:54:28.177 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:54:37.471 : ===>Input:[4,3,180,188] output:[4,3,720,752]
22-01-07 14:56:06.487 : 

22-01-07 14:56:06.487 : #################### Trainning Resumed ####################
22-01-07 14:56:06.675 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:56:17.780 : ===>Input:[4,3,164,160] output:[4,3,656,640]
22-01-07 14:58:51.282 : 

22-01-07 14:58:51.283 : #################### Trainning Resumed ####################
22-01-07 14:58:51.620 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:59:00.565 : ===>Input:[4,3,144,236] output:[4,3,576,944]
22-01-07 15:00:05.895 : 

22-01-07 15:00:05.895 : #################### Trainning Resumed ####################
22-01-07 15:00:06.261 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:00:12.982 : ===>Input:[4,3,208,152] output:[4,3,832,608]
22-01-07 15:00:49.301 : 

22-01-07 15:00:49.301 : #################### Trainning Resumed ####################
22-01-07 15:00:49.360 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:00:59.813 : ===>Input:[4,3,144,232] output:[4,3,576,928]
22-01-07 15:02:16.515 : 

22-01-07 15:02:16.515 : #################### Trainning Resumed ####################
22-01-07 15:02:16.574 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:02:29.254 : ===>Input:[4,3,128,256] output:[4,3,512,1024]
22-01-07 15:03:31.501 : 

22-01-07 15:03:31.501 : #################### Trainning Resumed ####################
22-01-07 15:03:31.799 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:03:37.803 : ===>Input:[4,3,128,144] output:[4,3,512,576]
22-01-07 15:05:43.522 : 

22-01-07 15:05:43.522 : #################### Trainning Resumed ####################
22-01-07 15:05:43.589 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:05:56.037 : ===>Input:[4,3,176,176] output:[4,3,704,704]
22-01-07 15:07:51.247 : 

22-01-07 15:07:51.247 : #################### Trainning Resumed ####################
22-01-07 15:08:32.451 : 

22-01-07 15:08:32.451 : #################### Trainning Resumed ####################
22-01-07 15:08:32.856 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:08:42.673 : ===>Input:[4,3,164,220] output:[4,3,656,880]
22-01-07 15:09:57.940 : 

22-01-07 15:09:57.940 : #################### Trainning Resumed ####################
22-01-07 15:09:58.385 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:10:08.249 : ===>Input:[4,3,228,256] output:[4,3,912,1024]
22-01-07 15:14:41.250 : 

22-01-07 15:14:41.250 : #################### Trainning Resumed ####################
22-01-07 15:14:41.307 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:14:51.253 : ===>Input:[4,3,172,248] output:[4,3,688,992]
22-01-07 15:14:51.370 :        DEVICE ID : cuda
22-01-07 15:14:57.744 : L1 loss function
22-01-07 15:14:57.747 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:15:44.578 : 

22-01-07 15:15:44.579 : #################### Trainning Resumed ####################
22-01-07 15:15:44.875 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:16:02.757 : ===>Input:[8,3,256,256] output:[8,3,1024,1024]
22-01-07 15:16:02.871 :        DEVICE ID : cuda
22-01-07 15:16:09.184 : L1 loss function
22-01-07 15:16:09.185 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:17:14.871 : 

22-01-07 15:17:14.871 : #################### Trainning Resumed ####################
22-01-07 15:17:15.416 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:17:41.800 : ===>Input:[8,3,200,200] output:[8,3,800,800]
22-01-07 15:17:41.903 :        DEVICE ID : cuda
22-01-07 15:17:47.973 : L1 loss function
22-01-07 15:17:47.974 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:19:54.463 : 

22-01-07 15:19:54.463 : #################### Trainning Resumed ####################
22-01-07 15:19:54.926 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:20:23.988 : ===>Input:[8,3,210,210] output:[8,3,840,840]
22-01-07 15:20:24.223 :        DEVICE ID : cuda
22-01-07 15:20:28.704 : L1 loss function
22-01-07 15:20:28.744 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:21:27.409 : 

22-01-07 15:21:27.410 : #################### Trainning Resumed ####################
22-01-07 15:21:28.000 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:21:46.573 : ===>Input:[8,3,200,200] output:[8,3,800,800]
22-01-07 15:21:46.684 :        DEVICE ID : cuda
22-01-07 15:21:52.869 : L1 loss function
22-01-07 15:21:52.871 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:26:20.359 : 

22-01-07 15:26:20.359 : #################### Trainning Resumed ####################
22-01-07 15:26:21.008 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:26:45.455 : ===>Input:[8,3,200,200] output:[8,3,800,800]
22-01-07 15:26:45.578 :        DEVICE ID : cuda
22-01-07 15:26:51.803 : L1 loss function
22-01-07 15:26:51.805 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:28:39.099 : 

22-01-07 15:28:39.099 : #################### Trainning Resumed ####################
22-01-07 15:28:39.660 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:28:59.283 : ===>Input:[8,3,200,200] output:[8,3,800,800]
22-01-07 15:28:59.397 :        DEVICE ID : cuda
22-01-07 15:29:05.476 : L1 loss function
22-01-07 15:29:05.478 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:29:51.573 : 

22-01-07 15:29:51.573 : #################### Trainning Resumed ####################
22-01-07 15:29:52.135 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:30:14.930 : ===>Input:[8,3,190,190] output:[8,3,760,760]
22-01-07 15:30:15.081 :        DEVICE ID : cuda
22-01-07 15:30:18.445 : L1 loss function
22-01-07 15:30:18.448 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:31:49.047 : 

22-01-07 15:31:49.048 : #################### Trainning Resumed ####################
22-01-07 15:31:49.620 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:32:13.265 : ===>Input:[8,3,198,198] output:[8,3,792,792]
22-01-07 15:32:13.377 :        DEVICE ID : cuda
22-01-07 15:32:19.113 : L1 loss function
22-01-07 15:32:19.115 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:33:33.834 : 

22-01-07 15:33:33.836 : #################### Trainning Resumed ####################
22-01-07 15:33:34.515 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:33:55.492 : ===>Input:[8,3,190,190] output:[8,3,760,760]
22-01-07 15:33:55.605 :        DEVICE ID : cuda
22-01-07 15:34:01.566 : L1 loss function
22-01-07 15:34:01.567 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:35:43.870 : 

22-01-07 15:35:43.871 : #################### Trainning Resumed ####################
22-01-07 15:35:44.453 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:36:08.977 : 

22-01-07 15:36:08.977 : #################### Trainning Resumed ####################
22-01-07 15:36:09.101 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:36:41.031 : ===>Input:[8,3,192,152] output:[8,3,768,608]
22-01-07 15:36:41.175 :        DEVICE ID : cuda
22-01-07 15:36:49.477 : L1 loss function
22-01-07 15:36:49.478 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:39:33.992 : 

22-01-07 15:39:33.992 : #################### Trainning Resumed ####################
22-01-07 15:39:34.451 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:39:49.194 : ===>Input:[8,3,200,144] output:[8,3,800,576]
22-01-07 15:39:49.271 :        DEVICE ID : cuda
22-01-07 15:39:56.085 : L1 loss function
22-01-07 15:39:56.086 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:46:14.710 : 

22-01-07 15:46:14.710 : #################### Trainning Resumed ####################
22-01-07 15:46:15.320 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:46:39.904 : ===>Input:[8,3,248,132] output:[8,3,992,528]
22-01-07 15:46:39.981 :        DEVICE ID : cuda
22-01-07 15:46:47.522 : L1 loss function
22-01-07 15:46:47.523 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:47:23.976 : 

22-01-07 15:47:23.977 : #################### Trainning Resumed ####################
22-01-07 15:47:24.493 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:47:39.899 : ===>Input:[8,3,190,190] output:[8,3,760,760]
22-01-07 15:47:39.973 :        DEVICE ID : cuda
22-01-07 15:47:44.950 : L1 loss function
22-01-07 15:47:44.951 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:48:53.482 : 

22-01-07 15:48:53.482 : #################### Trainning Resumed ####################
22-01-07 15:48:53.846 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:49:04.736 : ===>Input:[8,3,168,136] output:[8,3,672,544]
22-01-07 15:49:04.841 :        DEVICE ID : cuda
22-01-07 15:49:10.498 : L1 loss function
22-01-07 15:49:10.499 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 16:22:39.788 : ===> Epoch[0]: Loss_l1: 0.05305  Duration: 33.488385 min
22-01-07 16:30:32.923 : ===> Valid. psnr: 25.5959, ssim: 0.6634, loss: 0.0394
22-01-07 16:30:33.166 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_0.pth
22-01-07 16:30:33.166 : 

22-01-07 16:30:33.167 : ===> TrainEpoch =1  lr = 0.0001
22-01-07 17:07:39.227 : ===> Epoch[1]: Loss_l1: 0.03931  Duration: 37.101483 min
22-01-07 17:15:31.087 : ===> Valid. psnr: 26.2568, ssim: 0.6796, loss: 0.0372
22-01-07 17:15:31.237 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_1.pth
22-01-07 17:15:31.237 : 

22-01-07 17:15:31.239 : ===> TrainEpoch =2  lr = 0.0001
22-01-07 17:54:31.578 : ===> Epoch[2]: Loss_l1: 0.03797  Duration: 39.005496 min
22-01-07 18:02:52.391 : ===> Valid. psnr: 26.3239, ssim: 0.6830, loss: 0.0372
22-01-07 18:02:52.566 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_2.pth
22-01-07 18:02:52.566 : 

22-01-07 18:11:04.526 : 

22-01-07 18:11:04.526 : #################### Trainning Resumed ####################
22-01-07 18:11:04.954 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 18:11:16.556 : ===>Input:[8,3,176,160] output:[8,3,704,640]
22-01-07 18:11:16.657 :        DEVICE ID : cuda
22-01-07 18:11:24.206 : L1 loss function
22-01-07 18:11:24.372 : ===> TrainEpoch =3  lr = 0.0001
22-01-07 18:51:15.955 : ===> Epoch[3]: Loss_l1: 0.03807  Duration: 39.860792 min
22-01-07 18:59:43.131 : ===> Valid. psnr: 26.6043, ssim: 0.6850, loss: 0.0364
22-01-07 18:59:43.282 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_3.pth
22-01-07 18:59:43.282 : 

22-01-07 18:59:43.283 : ===> TrainEpoch =4  lr = 0.0001
22-01-07 19:00:32.353 : 

22-01-07 19:00:32.353 : #################### Trainning Resumed ####################
22-01-07 19:00:32.581 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:00:35.678 : ===>Input:[4,3,166,180] output:[4,3,498,540]
22-01-07 19:01:30.665 : 

22-01-07 19:01:30.665 : #################### Trainning Resumed ####################
22-01-07 19:01:30.725 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:01:36.480 : ===>Input:[4,3,202,166] output:[4,3,606,498]
22-01-07 19:03:01.341 : 

22-01-07 19:03:01.341 : #################### Trainning Resumed ####################
22-01-07 19:03:01.432 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:03:05.168 : ===>Input:[4,3,146,148] output:[4,3,438,444]
22-01-07 19:05:59.857 : 

22-01-07 19:05:59.857 : #################### Trainning Resumed ####################
22-01-07 19:05:59.912 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:06:06.254 : ===>Input:[4,3,200,168] output:[4,3,600,504]
22-01-07 19:06:34.801 : 

22-01-07 19:06:34.801 : #################### Trainning Resumed ####################
22-01-07 19:06:34.863 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:06:41.336 : ===>Input:[4,3,148,194] output:[4,3,444,582]
22-01-07 19:07:19.755 : 

22-01-07 19:07:19.755 : #################### Trainning Resumed ####################
22-01-07 19:07:19.817 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:07:24.789 : ===>Input:[4,3,128,204] output:[4,3,384,612]
22-01-07 19:08:16.817 : 

22-01-07 19:08:16.817 : #################### Trainning Resumed ####################
22-01-07 19:08:16.876 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:08:23.265 : ===>Input:[4,3,226,146] output:[4,3,678,438]
22-01-07 19:37:42.682 : 

22-01-07 19:37:42.682 : #################### Trainning Resumed ####################
22-01-07 19:37:42.768 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:37:50.794 : ===>Input:[4,3,128,208] output:[4,3,384,624]
22-01-07 19:37:50.870 :        DEVICE ID : cuda
22-01-07 19:37:58.755 : L1 loss function
22-01-07 19:37:58.758 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:39:18.163 : 

22-01-07 19:39:18.163 : #################### Trainning Resumed ####################
22-01-07 19:39:18.631 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:39:21.949 : ===>Input:[4,3,148,174] output:[4,3,444,522]
22-01-07 19:39:22.011 :        DEVICE ID : cuda
22-01-07 19:39:25.544 : L1 loss function
22-01-07 19:39:25.545 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:40:27.946 : 

22-01-07 19:40:27.946 : #################### Trainning Resumed ####################
22-01-07 19:40:28.151 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:40:32.144 : ===>Input:[4,3,138,212] output:[4,3,414,636]
22-01-07 19:40:32.208 :        DEVICE ID : cuda
22-01-07 19:40:35.841 : L1 loss function
22-01-07 19:40:35.843 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:41:00.294 : 

22-01-07 19:41:00.294 : #################### Trainning Resumed ####################
22-01-07 19:41:00.541 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:41:05.505 : ===>Input:[4,3,180,154] output:[4,3,540,462]
22-01-07 19:41:05.564 :        DEVICE ID : cuda
22-01-07 19:41:09.185 : L1 loss function
22-01-07 19:41:09.186 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:41:29.320 : 

22-01-07 19:41:29.320 : #################### Trainning Resumed ####################
22-01-07 19:41:29.376 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:41:35.710 : ===>Input:[4,3,202,156] output:[4,3,606,468]
22-01-07 19:41:35.782 :        DEVICE ID : cuda
22-01-07 19:41:39.608 : L1 loss function
22-01-07 19:41:39.609 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:43:27.908 : 

22-01-07 19:43:27.909 : #################### Trainning Resumed ####################
22-01-07 19:43:28.107 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:43:30.994 : ===>Input:[4,3,190,190] output:[4,3,570,570]
22-01-07 19:43:31.051 :        DEVICE ID : cuda
22-01-07 19:43:34.655 : L1 loss function
22-01-07 19:43:34.656 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:44:00.392 : 

22-01-07 19:44:00.393 : #################### Trainning Resumed ####################
22-01-07 19:44:00.781 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:44:05.984 : ===>Input:[4,3,220,220] output:[4,3,660,660]
22-01-07 19:44:06.043 :        DEVICE ID : cuda
22-01-07 19:44:09.652 : L1 loss function
22-01-07 19:44:09.653 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:44:32.679 : 

22-01-07 19:44:32.679 : #################### Trainning Resumed ####################
22-01-07 19:44:32.869 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:44:36.719 : ===>Input:[4,3,240,240] output:[4,3,720,720]
22-01-07 19:44:36.779 :        DEVICE ID : cuda
22-01-07 19:44:40.304 : L1 loss function
22-01-07 19:44:40.305 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:45:36.338 : 

22-01-07 19:45:36.339 : #################### Trainning Resumed ####################
22-01-07 19:45:36.650 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 19:45:46.659 : ===>Input:[8,3,190,190] output:[8,3,570,570]
22-01-07 19:45:46.719 :        DEVICE ID : cuda
22-01-07 19:45:50.288 : L1 loss function
22-01-07 19:45:50.289 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:46:15.537 : 

22-01-07 19:46:15.537 : #################### Trainning Resumed ####################
22-01-07 19:46:15.770 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 19:46:26.457 : ===>Input:[8,3,180,180] output:[8,3,540,540]
22-01-07 19:46:26.516 :        DEVICE ID : cuda
22-01-07 19:46:30.162 : L1 loss function
22-01-07 19:46:30.163 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:47:05.641 : 

22-01-07 19:47:05.641 : #################### Trainning Resumed ####################
22-01-07 19:47:05.732 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 19:47:16.507 : ===>Input:[8,3,170,170] output:[8,3,510,510]
22-01-07 19:47:16.568 :        DEVICE ID : cuda
22-01-07 19:47:20.046 : L1 loss function
22-01-07 19:47:20.047 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:48:06.966 : 

22-01-07 19:48:06.968 : #################### Trainning Resumed ####################
22-01-07 19:48:07.576 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 19:48:15.003 : ===>Input:[8,3,146,132] output:[8,3,438,396]
22-01-07 19:48:15.083 :        DEVICE ID : cuda
22-01-07 19:48:21.732 : L1 loss function
22-01-07 19:48:21.733 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 20:23:15.855 : ===> Epoch[0]: Loss_l1: 0.05622  Duration: 34.900663 min
22-01-07 20:29:50.442 : ===> Valid. psnr: 25.8596, ssim: 0.6656, loss: 0.0399
22-01-07 20:29:50.696 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_0.pth
22-01-07 20:29:50.697 : 

22-01-07 20:29:50.698 : ===> TrainEpoch =1  lr = 0.0001
22-01-07 21:04:26.748 : ===> Epoch[1]: Loss_l1: 0.03828  Duration: 34.601477 min
22-01-07 21:10:50.419 : ===> Valid. psnr: 26.7811, ssim: 0.6925, loss: 0.0362
22-01-07 21:10:50.536 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_1.pth
22-01-07 21:10:50.536 : 

22-01-07 21:12:29.433 : 

22-01-07 21:12:29.433 : #################### Trainning Resumed ####################
22-01-07 21:12:29.704 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 21:12:51.180 : ===>Input:[8,3,162,152] output:[8,3,486,456]
22-01-07 21:12:51.267 :        DEVICE ID : cuda
22-01-07 21:12:58.749 : L1 loss function
22-01-07 21:12:58.964 : ===> TrainEpoch =2  lr = 0.0001
22-01-07 21:52:30.197 : ===> Epoch[2]: Loss_l1: 0.03646  Duration: 39.520942 min
22-01-07 22:00:07.779 : ===> Valid. psnr: 27.0063, ssim: 0.7088, loss: 0.0353
22-01-07 22:00:07.956 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_2.pth
22-01-07 22:00:07.956 : 

22-01-08 10:11:43.877 : 

22-01-08 10:11:43.877 : #################### Trainning Resumed ####################
22-01-08 10:11:44.572 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 10:12:12.444 : ===>Input:[8,3,164,128] output:[8,3,492,384]
22-01-08 10:12:12.590 :        DEVICE ID : cuda
22-01-08 10:12:20.754 : L1 loss function
22-01-08 10:12:20.908 : ===> TrainEpoch =3  lr = 0.0001
22-01-08 10:49:49.875 : ===> Epoch[3]: Loss_l1: 0.03544  Duration: 37.485433 min
22-01-08 10:57:14.256 : ===> Valid. psnr: 27.1956, ssim: 0.7086, loss: 0.0346
22-01-08 10:57:14.509 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_3.pth
22-01-08 10:57:14.509 : 

22-01-08 10:57:14.515 : ===> TrainEpoch =4  lr = 0.0001
22-01-08 11:41:46.009 : 

22-01-08 11:41:46.010 : #################### Trainning Resumed ####################
22-01-08 11:41:46.592 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 11:41:53.604 : 

22-01-08 11:41:53.604 : #################### Trainning Resumed ####################
22-01-08 11:41:53.662 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 11:42:01.811 : ===>Input:[8,3,138,176] output:[8,3,414,528]
22-01-08 11:42:01.889 :        DEVICE ID : cuda
22-01-08 11:42:12.657 : L1 loss function
22-01-08 11:42:12.789 : ===> TrainEpoch =4  lr = 0.0001
22-01-08 12:25:23.248 : ===> Epoch[4]: Loss_l1: 0.03422  Duration: 43.175821 min
22-01-08 12:32:05.478 : ===> Valid. psnr: 27.6483, ssim: 0.7176, loss: 0.0326
22-01-08 12:32:05.647 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_4.pth
22-01-08 12:32:05.647 : 

22-01-08 12:32:05.648 : ===> TrainEpoch =5  lr = 0.0001
22-01-08 13:17:43.770 : ===> Epoch[5]: Loss_l1: 0.03371  Duration: 45.635958 min
22-01-08 13:26:47.948 : ===> Valid. psnr: 27.5755, ssim: 0.7210, loss: 0.0332
22-01-08 13:26:48.158 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_5.pth
22-01-08 13:26:48.158 : 

22-01-08 13:35:33.374 : 

22-01-08 13:35:33.375 : #################### Trainning Resumed ####################
22-01-08 13:35:33.885 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 13:35:46.861 : ===>Input:[8,3,170,170] output:[8,3,510,510]
22-01-08 13:35:46.942 :        DEVICE ID : cuda
22-01-08 13:35:54.688 : L1 loss function
22-01-08 13:35:54.689 : ===> TrainEpoch =0  lr = 0.0001
22-01-08 13:36:30.192 : 

22-01-08 13:36:30.194 : #################### Trainning Resumed ####################
22-01-08 13:36:30.655 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 13:36:41.270 : ===>Input:[8,3,170,180] output:[8,3,510,540]
22-01-08 13:36:41.349 :        DEVICE ID : cuda
22-01-08 13:36:46.601 : L1 loss function
22-01-08 13:36:46.602 : ===> TrainEpoch =0  lr = 0.0001
22-01-08 13:37:24.980 : 

22-01-08 13:37:24.980 : #################### Trainning Resumed ####################
22-01-08 13:37:25.440 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 13:37:32.942 : ===>Input:[8,3,130,172] output:[8,3,390,516]
22-01-08 13:37:33.008 :        DEVICE ID : cuda
22-01-08 13:37:36.918 : L1 loss function
22-01-08 13:37:36.919 : ===> TrainEpoch =0  lr = 0.0001
22-01-08 13:51:39.225 : 

22-01-08 13:51:39.225 : #################### Trainning Resumed ####################
22-01-08 13:51:39.755 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 13:51:52.132 : ===>Input:[8,3,144,178] output:[8,3,432,534]
22-01-08 13:51:52.233 :        DEVICE ID : cuda
22-01-08 13:51:59.440 : L1 loss function
22-01-08 13:51:59.441 : ===> TrainEpoch =0  lr = 0.0001
22-01-08 14:35:50.952 : ===> Epoch[0]: Loss_l1: 0.05520  Duration: 43.857221 min
22-01-08 14:43:54.591 : ===> Valid. psnr: 26.0440, ssim: 0.6674, loss: 0.0392
22-01-08 14:43:55.031 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_0.pth
22-01-08 14:43:55.031 : 

22-01-08 14:43:55.037 : ===> TrainEpoch =1  lr = 0.0001
22-01-08 15:25:54.418 : ===> Epoch[1]: Loss_l1: 0.03837  Duration: 41.990908 min
22-01-08 15:32:30.097 : ===> Valid. psnr: 26.7365, ssim: 0.6886, loss: 0.0366
22-01-08 15:32:30.293 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_1.pth
22-01-08 15:32:30.294 : 

22-01-08 15:43:07.236 : 

22-01-08 15:43:07.236 : #################### Trainning Resumed ####################
22-01-08 15:43:07.495 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 15:43:17.453 : ===>Input:[8,3,142,172] output:[8,3,426,516]
22-01-08 15:43:17.538 :        DEVICE ID : cuda
22-01-08 15:43:25.141 : L1 loss function
22-01-08 15:43:25.195 : ===> TrainEpoch =2  lr = 0.0001
22-01-08 16:20:08.492 : ===> Epoch[2]: Loss_l1: 0.03691  Duration: 36.720717 min
22-01-08 16:26:55.768 : ===> Valid. psnr: 27.1986, ssim: 0.7019, loss: 0.0345
22-01-08 16:26:55.966 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_2.pth
22-01-08 16:26:55.966 : 

22-01-08 16:26:55.971 : ===> TrainEpoch =3  lr = 0.0001
22-01-08 17:03:08.445 : ===> Epoch[3]: Loss_l1: 0.03553  Duration: 36.207533 min
22-01-08 17:09:38.807 : ===> Valid. psnr: 27.4177, ssim: 0.7127, loss: 0.0337
22-01-08 17:09:38.921 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_3.pth
22-01-08 17:09:38.921 : 

22-01-08 17:09:38.921 : ===> TrainEpoch =4  lr = 0.0001
22-01-08 17:44:31.356 : ===> Epoch[4]: Loss_l1: 0.03486  Duration: 34.877383 min
22-01-08 17:51:07.814 : ===> Valid. psnr: 27.7178, ssim: 0.7190, loss: 0.0328
22-01-08 17:51:07.965 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_4.pth
22-01-08 17:51:07.965 : 

22-01-08 17:51:07.966 : ===> TrainEpoch =5  lr = 0.0001
22-01-08 18:28:03.397 : ===> Epoch[5]: Loss_l1: 0.03403  Duration: 36.922950 min
22-01-08 18:34:53.666 : ===> Valid. psnr: 27.5534, ssim: 0.7158, loss: 0.0334
22-01-08 18:34:53.797 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_5.pth
22-01-08 18:34:53.797 : 

22-01-08 18:34:53.798 : ===> TrainEpoch =6  lr = 0.0001
22-01-08 19:09:56.043 : ===> Epoch[6]: Loss_l1: 0.03371  Duration: 35.038367 min
22-01-08 19:16:29.171 : ===> Valid. psnr: 27.6563, ssim: 0.7208, loss: 0.0327
22-01-08 19:16:29.231 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_6.pth
22-01-08 19:16:29.231 : 

22-01-08 19:22:12.757 : 

22-01-08 19:22:12.757 : #################### Trainning Resumed ####################
22-01-08 19:22:13.018 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 19:22:19.781 : ===>Input:[8,3,134,140] output:[8,3,402,420]
22-01-08 19:22:19.868 :        DEVICE ID : cuda
22-01-08 19:22:27.366 : L1 loss function
22-01-08 19:22:27.421 : ===> TrainEpoch =7  lr = 1e-05
22-01-08 20:02:42.052 : ===> Epoch[7]: Loss_l1: 0.03263  Duration: 40.244492 min
22-01-08 20:10:14.060 : ===> Valid. psnr: 28.1244, ssim: 0.7290, loss: 0.0312
22-01-08 20:10:14.182 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_7.pth
22-01-08 20:10:14.182 : 

22-01-08 20:11:42.210 : 

22-01-08 20:11:42.210 : #################### Trainning Resumed ####################
22-01-08 20:11:42.512 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 20:11:52.190 : ===>Input:[8,3,192,138] output:[8,3,576,414]
22-01-08 20:11:52.269 :        DEVICE ID : cuda
22-01-08 20:12:00.122 : L1 loss function
22-01-08 20:12:00.174 : ===> TrainEpoch =8  lr = 1e-05
22-01-08 20:48:26.550 : ===> Epoch[8]: Loss_l1: 0.03241  Duration: 36.439496 min
22-01-08 20:55:23.947 : ===> Valid. psnr: 27.9998, ssim: 0.7261, loss: 0.0316
22-01-08 20:55:24.031 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_8.pth
22-01-08 20:55:24.031 : 

22-01-09 08:18:40.490 : 

22-01-09 08:18:40.490 : #################### Trainning Resumed ####################
22-01-09 08:18:41.050 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 08:18:50.883 : ===>Input:[8,3,256,256] output:[8,3,1024,1024]
22-01-09 08:19:02.981 : 

22-01-09 08:19:02.982 : #################### Trainning Resumed ####################
22-01-09 08:19:03.038 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 08:19:13.716 : ===>Input:[8,3,256,256] output:[8,3,1024,1024]
22-01-09 08:19:13.818 :        DEVICE ID : cuda
22-01-09 08:19:21.404 : L1 loss function
22-01-09 08:19:21.405 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 08:19:48.538 : 

22-01-09 08:19:48.538 : #################### Trainning Resumed ####################
22-01-09 08:19:48.909 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 08:19:56.948 : ===>Input:[8,3,170,170] output:[8,3,680,680]
22-01-09 08:19:57.011 :        DEVICE ID : cuda
22-01-09 08:20:00.848 : L1 loss function
22-01-09 08:20:00.849 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 08:20:53.659 : 

22-01-09 08:20:53.659 : #################### Trainning Resumed ####################
22-01-09 08:20:53.717 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 08:21:04.153 : ===>Input:[8,3,170,170] output:[8,3,680,680]
22-01-09 08:21:04.213 :        DEVICE ID : cuda
22-01-09 08:21:08.558 : L1 loss function
22-01-09 08:21:08.559 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 08:21:44.097 : 

22-01-09 08:21:44.097 : #################### Trainning Resumed ####################
22-01-09 08:21:44.154 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 08:21:52.720 : ===>Input:[8,3,170,170] output:[8,3,680,680]
22-01-09 08:21:52.776 :        DEVICE ID : cuda
22-01-09 08:21:56.249 : L1 loss function
22-01-09 08:21:56.249 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 08:22:53.725 : 

22-01-09 08:22:53.726 : #################### Trainning Resumed ####################
22-01-09 08:22:53.782 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-09 08:23:00.488 : ===>Input:[4,3,200,200] output:[4,3,800,800]
22-01-09 08:23:00.549 :        DEVICE ID : cuda
22-01-09 08:23:03.986 : L1 loss function
22-01-09 08:23:03.987 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 08:23:29.627 : 

22-01-09 08:23:29.628 : #################### Trainning Resumed ####################
22-01-09 08:23:29.683 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-09 08:23:33.013 : ===>Input:[4,3,190,190] output:[4,3,760,760]
22-01-09 08:23:33.068 :        DEVICE ID : cuda
22-01-09 08:23:36.606 : L1 loss function
22-01-09 08:23:36.606 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 08:24:15.697 : 

22-01-09 08:24:15.697 : #################### Trainning Resumed ####################
22-01-09 08:24:15.754 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-09 08:24:20.962 : ===>Input:[4,3,190,190] output:[4,3,760,760]
22-01-09 08:24:21.015 :        DEVICE ID : cuda
22-01-09 08:24:24.523 : L1 loss function
22-01-09 08:24:24.524 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 08:24:54.894 : 

22-01-09 08:24:54.894 : #################### Trainning Resumed ####################
22-01-09 08:24:54.952 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-09 08:24:58.678 : ===>Input:[4,3,140,140] output:[4,3,560,560]
22-01-09 08:24:58.733 :        DEVICE ID : cuda
22-01-09 08:25:02.278 : L1 loss function
22-01-09 08:25:02.279 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 08:25:23.141 : 

22-01-09 08:25:23.141 : #################### Trainning Resumed ####################
22-01-09 08:25:23.256 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-09 08:25:26.831 : ===>Input:[4,3,150,150] output:[4,3,600,600]
22-01-09 08:25:26.885 :        DEVICE ID : cuda
22-01-09 08:25:30.334 : L1 loss function
22-01-09 08:25:30.335 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 08:25:54.638 : 

22-01-09 08:25:54.638 : #################### Trainning Resumed ####################
22-01-09 08:25:54.694 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-09 08:25:58.623 : ===>Input:[4,3,170,170] output:[4,3,680,680]
22-01-09 08:25:58.676 :        DEVICE ID : cuda
22-01-09 08:26:02.159 : L1 loss function
22-01-09 08:26:02.160 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 08:26:48.971 : 

22-01-09 08:26:49.060 : #################### Trainning Resumed ####################
22-01-09 08:26:49.243 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-09 08:26:53.591 : ===>Input:[4,3,154,146] output:[4,3,616,584]
22-01-09 08:26:53.648 :        DEVICE ID : cuda
22-01-09 08:26:57.699 : L1 loss function
22-01-09 08:26:57.700 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 09:28:33.133 : 

22-01-09 09:28:33.133 : #################### Trainning Resumed ####################
22-01-09 09:28:33.810 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-09 09:28:40.067 : ===>Input:[4,3,182,190] output:[4,3,728,760]
22-01-09 09:28:40.159 :        DEVICE ID : cuda
22-01-09 09:28:43.262 : L1 loss function
22-01-09 09:28:43.263 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 09:30:27.081 : 

22-01-09 09:30:27.082 : #################### Trainning Resumed ####################
22-01-09 09:30:27.692 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-09 09:30:32.921 : ===>Input:[4,3,136,132] output:[4,3,544,528]
22-01-09 09:30:32.985 :        DEVICE ID : cuda
22-01-09 09:30:36.124 : L1 loss function
22-01-09 09:30:36.125 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 10:38:50.109 : ===> Epoch[0]: Loss_l1: 0.04309  Duration: 68.234308 min
22-01-09 10:48:58.887 : ===> Valid. psnr: 26.8961, ssim: 0.6966, loss: 0.0353
22-01-09 10:48:59.135 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_0.pth
22-01-09 10:48:59.135 : 

