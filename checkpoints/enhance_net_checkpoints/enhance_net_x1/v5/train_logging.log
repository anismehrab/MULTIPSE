22-05-10 11:21:02.071 : 

22-05-10 11:21:02.071 : #################### Trainning Resumed ####################
22-05-10 11:21:03.102 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 11:21:26.114 : ===>Input:[8,3,360,360] output:[8,3,360,360]
22-05-10 11:21:26.236 :        DEVICE ID : cuda
22-05-10 11:21:32.291 : L1 loss function
22-05-10 11:21:32.292 : ===> TrainEpoch =0  lr = 0.0002
22-05-10 11:23:52.831 : 

22-05-10 11:23:52.831 : #################### Trainning Resumed ####################
22-05-10 11:23:53.907 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 11:24:06.915 : ===>Input:[8,3,360,360] output:[8,3,360,360]
22-05-10 11:24:06.996 :        DEVICE ID : cuda
22-05-10 11:24:13.122 : L1 loss function
22-05-10 11:24:13.124 : ===> TrainEpoch =0  lr = 0.0002
22-05-10 11:27:37.622 : 

22-05-10 11:27:37.623 : #################### Trainning Resumed ####################
22-05-10 11:27:38.708 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:1
22-05-10 11:27:41.997 : ===>Input:[1,3,360,360] output:[1,3,360,360]
22-05-10 11:27:42.086 :        DEVICE ID : cuda
22-05-10 11:27:46.246 : L1 loss function
22-05-10 11:27:46.247 : ===> TrainEpoch =0  lr = 0.0002
22-05-10 11:28:46.452 : 

22-05-10 11:28:46.452 : #################### Trainning Resumed ####################
22-05-10 11:28:46.500 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:1
22-05-10 11:28:49.685 : ===>Input:[1,3,360,360] output:[1,3,360,360]
22-05-10 11:28:49.747 :        DEVICE ID : cuda
22-05-10 11:28:52.305 : L1 loss function
22-05-10 11:28:52.307 : ===> TrainEpoch =0  lr = 0.0002
22-05-10 11:29:32.947 : 

22-05-10 11:29:32.947 : #################### Trainning Resumed ####################
22-05-10 11:29:32.994 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:1
22-05-10 11:29:37.381 : ===>Input:[1,3,360,360] output:[1,3,360,360]
22-05-10 11:29:37.443 :        DEVICE ID : cuda
22-05-10 11:29:39.987 : L1 loss function
22-05-10 11:29:39.989 : ===> TrainEpoch =0  lr = 0.0002
22-05-10 11:30:47.616 : 

22-05-10 11:30:47.616 : #################### Trainning Resumed ####################
22-05-10 11:30:47.814 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:1
22-05-10 11:30:51.234 : ===>Input:[1,3,360,360] output:[1,3,360,360]
22-05-10 11:30:51.301 :        DEVICE ID : cuda
22-05-10 11:30:53.929 : L1 loss function
22-05-10 11:30:53.931 : ===> TrainEpoch =0  lr = 0.0002
22-05-10 11:38:08.428 : 

22-05-10 11:38:08.428 : #################### Trainning Resumed ####################
22-05-10 11:38:08.474 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:1
22-05-10 11:38:12.911 : ===>Input:[1,3,360,360] output:[1,3,360,360]
22-05-10 11:38:12.974 :        DEVICE ID : cuda
22-05-10 11:38:15.425 : L1 loss function
22-05-10 11:38:15.426 : ===> TrainEpoch =0  lr = 0.0002
22-05-10 11:39:21.340 : 

22-05-10 11:39:21.340 : #################### Trainning Resumed ####################
22-05-10 11:39:21.386 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:1
22-05-10 11:39:26.017 : ===>Input:[1,3,360,360] output:[1,3,360,360]
22-05-10 11:39:26.081 :        DEVICE ID : cuda
22-05-10 11:39:28.601 : L1 loss function
22-05-10 11:39:28.602 : ===> TrainEpoch =0  lr = 0.0002
22-05-10 11:49:25.301 : 

22-05-10 11:49:25.301 : #################### Trainning Resumed ####################
22-05-10 11:49:27.218 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:1
22-05-10 11:49:30.885 : ===>Input:[1,3,360,360] output:[1,3,360,360]
22-05-10 11:49:30.949 :        DEVICE ID : cuda
22-05-10 11:49:33.413 : L1 loss function
22-05-10 11:49:33.415 : ===> TrainEpoch =0  lr = 0.0002
22-05-10 11:50:01.818 : 

22-05-10 11:50:01.819 : #################### Trainning Resumed ####################
22-05-10 11:50:02.616 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 11:50:17.493 : ===>Input:[8,3,360,360] output:[8,3,360,360]
22-05-10 11:50:17.566 :        DEVICE ID : cuda
22-05-10 11:50:20.010 : L1 loss function
22-05-10 11:50:20.012 : ===> TrainEpoch =0  lr = 0.0002
22-05-10 14:09:44.055 : ===> Epoch[0]: Loss_l1: 0.04815  Duration: 139.402075 min
22-05-10 14:24:54.579 : ===> Valid. psnr: 25.6801, ssim: 0.6954, loss: 0.0357
22-05-10 14:24:54.730 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/enhance_net_x1/v5/checkpoint_base_epoch_0.pth
22-05-10 14:24:54.730 : 

22-05-10 16:19:24.596 : 

22-05-10 16:19:24.596 : #################### Trainning Resumed ####################
22-05-10 16:19:33.496 : 

22-05-10 16:19:33.497 : #################### Trainning Resumed ####################
22-05-10 16:19:33.733 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 16:19:50.009 : ===>Input:[8,3,432,276] output:[8,3,432,276]
22-05-10 16:19:50.071 :        DEVICE ID : cuda
22-05-10 16:19:52.633 : L1 loss function
22-05-10 16:19:52.727 : ===> TrainEpoch =1  lr = 0.0002
22-05-10 17:17:13.018 : 

22-05-10 17:17:13.018 : #################### Trainning Resumed ####################
22-05-10 17:17:13.313 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 17:17:38.938 : ===>Input:[8,3,438,264] output:[8,3,438,264]
22-05-10 17:17:39.044 :        DEVICE ID : cuda
22-05-10 17:17:41.993 : L1 loss function
22-05-10 17:17:42.134 : ===> TrainEpoch =1  lr = 0.0002
22-05-10 17:21:23.928 : 

22-05-10 17:21:23.929 : #################### Trainning Resumed ####################
22-05-10 17:21:24.171 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 17:21:49.748 : ===>Input:[8,3,258,312] output:[8,3,258,312]
22-05-10 17:21:49.867 :        DEVICE ID : cuda
22-05-10 17:21:55.597 : L1 loss function
22-05-10 17:21:55.746 : ===> TrainEpoch =1  lr = 0.0002
22-05-10 17:30:57.179 : 

22-05-10 17:30:57.180 : #################### Trainning Resumed ####################
22-05-10 17:30:57.437 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 17:31:14.123 : ===>Input:[8,3,288,372] output:[8,3,288,372]
22-05-10 17:31:14.227 :        DEVICE ID : cuda
22-05-10 17:31:18.607 : L1 loss function
22-05-10 17:31:18.764 : ===> TrainEpoch =1  lr = 0.0002
22-05-10 17:33:39.694 : 

22-05-10 17:33:39.694 : #################### Trainning Resumed ####################
22-05-10 17:33:39.929 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 17:34:00.880 : ===>Input:[8,3,258,462] output:[8,3,258,462]
22-05-10 17:34:00.985 :        DEVICE ID : cuda
22-05-10 17:34:05.862 : L1 loss function
22-05-10 17:34:06.008 : ===> TrainEpoch =1  lr = 0.0002
22-05-10 17:49:04.764 : 

22-05-10 17:49:04.764 : #################### Trainning Resumed ####################
22-05-10 17:49:04.999 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 17:49:26.905 : ===>Input:[8,3,360,360] output:[8,3,360,360]
22-05-10 17:49:27.031 :        DEVICE ID : cuda
22-05-10 17:49:32.612 : L1 loss function
22-05-10 17:49:32.772 : ===> TrainEpoch =1  lr = 0.0002
22-05-10 17:55:29.325 : 

22-05-10 17:55:29.325 : #################### Trainning Resumed ####################
22-05-10 17:55:29.566 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 17:55:53.305 : ===>Input:[8,3,456,258] output:[8,3,456,258]
22-05-10 17:55:53.415 :        DEVICE ID : cuda
22-05-10 17:55:59.070 : L1 loss function
22-05-10 17:55:59.218 : ===> TrainEpoch =1  lr = 0.0002
22-05-10 18:02:04.347 : 

22-05-10 18:02:04.347 : #################### Trainning Resumed ####################
22-05-10 18:02:04.592 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 18:02:23.941 : ===>Input:[8,3,392,296] output:[8,3,392,296]
22-05-10 18:02:24.045 :        DEVICE ID : cuda
22-05-10 18:02:28.492 : L1 loss function
22-05-10 18:02:28.645 : ===> TrainEpoch =1  lr = 0.0002
22-05-10 18:09:00.054 : 

22-05-10 18:09:00.054 : #################### Trainning Resumed ####################
22-05-10 18:09:00.285 : ===>Trainning Data:[ Train:9988  Valid:1998] Batch:8
22-05-10 18:09:17.240 : ===>Input:[8,3,344,344] output:[8,3,344,344]
22-05-10 18:09:17.382 :        DEVICE ID : cuda
22-05-10 18:09:22.169 : L1 loss function
22-05-10 18:09:22.332 : ===> TrainEpoch =1  lr = 0.0002
