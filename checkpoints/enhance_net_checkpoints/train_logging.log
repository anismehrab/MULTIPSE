22-01-02 16:52:42.723 : 

22-01-02 16:52:42.723 : #################### Trainning Resumed ####################
22-01-02 16:52:43.387 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-02 16:52:52.705 : ===>Input:[4,3,130,83] output:[4,3,520,332]
22-01-02 16:52:52.816 :        DEVICE ID : cuda
22-01-02 16:52:59.920 : L1 loss function
22-01-02 16:52:59.948 : ===> TrainEpoch =0  lr = 0.0001
22-01-02 16:55:12.107 : 

22-01-02 16:55:12.108 : #################### Trainning Resumed ####################
22-01-02 16:55:12.741 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-02 16:55:25.158 : ===>Input:[4,3,152,100] output:[4,3,608,400]
22-01-02 16:55:25.258 :        DEVICE ID : cuda
22-01-02 16:55:31.762 : L1 loss function
22-01-02 16:55:31.764 : ===> TrainEpoch =0  lr = 0.0001
22-01-02 16:57:00.448 : 

22-01-02 16:57:00.448 : #################### Trainning Resumed ####################
22-01-02 16:57:01.048 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-02 16:57:10.537 : ===>Input:[4,3,144,105] output:[4,3,432,315]
22-01-02 16:57:10.623 :        DEVICE ID : cuda
22-01-02 16:57:13.510 : L1 loss function
22-01-02 16:57:13.511 : ===> TrainEpoch =0  lr = 0.0001
22-01-02 17:00:05.114 : 

22-01-02 17:00:05.115 : #################### Trainning Resumed ####################
22-01-02 17:00:05.577 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-02 17:00:13.193 : ===>Input:[4,3,90,202] output:[4,3,270,606]
22-01-02 17:00:13.254 :        DEVICE ID : cuda
22-01-02 17:00:16.393 : L1 loss function
22-01-02 17:00:16.395 : ===> TrainEpoch =0  lr = 0.0001
22-01-02 17:01:49.754 : 

22-01-02 17:01:49.755 : #################### Trainning Resumed ####################
22-01-02 17:01:50.155 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-02 17:02:05.097 : ===>Input:[8,3,100,100] output:[8,3,300,300]
22-01-02 17:02:05.186 :        DEVICE ID : cuda
22-01-02 17:02:08.898 : L1 loss function
22-01-02 17:02:08.899 : ===> TrainEpoch =0  lr = 0.0001
22-01-02 17:03:04.476 : 

22-01-02 17:03:04.477 : #################### Trainning Resumed ####################
22-01-02 17:03:04.892 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-02 17:03:21.661 : ===>Input:[8,3,200,200] output:[8,3,600,600]
22-01-02 17:03:21.765 :        DEVICE ID : cuda
22-01-02 17:03:28.068 : L1 loss function
22-01-02 17:03:28.069 : ===> TrainEpoch =0  lr = 0.0001
22-01-02 17:04:24.449 : 

22-01-02 17:04:24.449 : #################### Trainning Resumed ####################
22-01-02 17:04:24.984 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-02 17:04:43.151 : ===>Input:[8,3,220,220] output:[8,3,660,660]
22-01-02 17:04:43.254 :        DEVICE ID : cuda
22-01-02 17:04:49.383 : L1 loss function
22-01-02 17:04:49.384 : ===> TrainEpoch =0  lr = 0.0001
22-01-02 17:05:38.876 : 

22-01-02 17:05:38.876 : #################### Trainning Resumed ####################
22-01-02 17:05:39.501 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-02 17:06:05.939 : ===>Input:[8,3,210,210] output:[8,3,630,630]
22-01-02 17:06:06.054 :        DEVICE ID : cuda
22-01-02 17:06:15.456 : L1 loss function
22-01-02 17:06:15.457 : ===> TrainEpoch =0  lr = 0.0001
