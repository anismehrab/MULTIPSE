
22-01-06 18:42:32.857 : #################### Trainning Resumed ####################
22-01-06 18:42:33.346 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-06 18:42:43.348 : ===>Input:[4,3,248,216] output:[4,3,992,864]
22-01-06 18:42:43.421 :        DEVICE ID : cuda
22-01-06 18:42:46.580 : L1 loss function
22-01-06 18:42:46.581 : ===> TrainEpoch =0  lr = 0.0001
22-01-06 19:22:33.713 : ===> Epoch[0]: Loss_l1: 0.06139  Duration: 39.785100 min
22-01-06 19:33:24.674 : ===> Valid. psnr: 25.2718, ssim: 0.6537, loss: 0.0410
22-01-06 19:33:24.777 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_0.pth
22-01-06 19:33:24.777 : 


2

22-01-07 11:18:52.073 : #################### Trainning Resumed ####################
22-01-07 11:18:52.322 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 11:18:57.113 : ===>Input:[4,3,148,160] output:[4,3,592,640]
22-01-07 11:18:57.182 :        DEVICE ID : cuda
22-01-07 11:19:01.148 : L1 loss function
22-01-07 11:19:01.200 : ===> TrainEpoch =1  lr = 0.0001
22-01-07 12:02:27.284 : ===> Epoch[1]: Loss_l1: 0.04148  Duration: 43.434921 min
22-01-07 12:13:14.568 : ===> Valid. psnr: 26.2269, ssim: 0.6808, loss: 0.0371
22-01-07 12:13:14.780 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_1.pth
22-01-07 12:13:14.780 : 

22-01-07 12:13:14.781 : ===> TrainEpoch =2  lr = 0.0001
22-01-07 14:36:36.357 : 

22-01-07 14:36:36.357 : #################### Trainning Resumed ####################
22-01-07 14:36:36.596 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:36:40.232 : ===>Input:[4,3,168,164] output:[4,3,672,656]
22-01-07 14:37:05.473 : 

22-01-07 14:37:05.473 : #################### Trainning Resumed ####################
22-01-07 14:37:05.550 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:37:08.762 : ===>Input:[4,3,152,256] output:[4,3,608,1024]
22-01-07 14:43:25.075 : 

22-01-07 14:43:25.075 : #################### Trainning Resumed ####################
22-01-07 14:43:25.131 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:43:30.601 : ===>Input:[4,3,256,208] output:[4,3,1024,832]
22-01-07 14:50:30.192 : 

22-01-07 14:50:30.192 : #################### Trainning Resumed ####################
22-01-07 14:50:30.297 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:50:35.688 : ===>Input:[4,3,172,224] output:[4,3,688,896]
22-01-07 14:51:51.247 : 

22-01-07 14:51:51.247 : #################### Trainning Resumed ####################
22-01-07 14:51:51.302 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:51:54.234 : ===>Input:[4,3,188,128] output:[4,3,752,512]
22-01-07 14:54:28.120 : 

22-01-07 14:54:28.120 : #################### Trainning Resumed ####################
22-01-07 14:54:28.177 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:54:37.471 : ===>Input:[4,3,180,188] output:[4,3,720,752]
22-01-07 14:56:06.487 : 

22-01-07 14:56:06.487 : #################### Trainning Resumed ####################
22-01-07 14:56:06.675 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:56:17.780 : ===>Input:[4,3,164,160] output:[4,3,656,640]
22-01-07 14:58:51.282 : 

22-01-07 14:58:51.283 : #################### Trainning Resumed ####################
22-01-07 14:58:51.620 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 14:59:00.565 : ===>Input:[4,3,144,236] output:[4,3,576,944]
22-01-07 15:00:05.895 : 

22-01-07 15:00:05.895 : #################### Trainning Resumed ####################
22-01-07 15:00:06.261 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:00:12.982 : ===>Input:[4,3,208,152] output:[4,3,832,608]
22-01-07 15:00:49.301 : 

22-01-07 15:00:49.301 : #################### Trainning Resumed ####################
22-01-07 15:00:49.360 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:00:59.813 : ===>Input:[4,3,144,232] output:[4,3,576,928]
22-01-07 15:02:16.515 : 

22-01-07 15:02:16.515 : #################### Trainning Resumed ####################
22-01-07 15:02:16.574 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:02:29.254 : ===>Input:[4,3,128,256] output:[4,3,512,1024]
22-01-07 15:03:31.501 : 

22-01-07 15:03:31.501 : #################### Trainning Resumed ####################
22-01-07 15:03:31.799 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:03:37.803 : ===>Input:[4,3,128,144] output:[4,3,512,576]
22-01-07 15:05:43.522 : 

22-01-07 15:05:43.522 : #################### Trainning Resumed ####################
22-01-07 15:05:43.589 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:05:56.037 : ===>Input:[4,3,176,176] output:[4,3,704,704]
22-01-07 15:07:51.247 : 

22-01-07 15:07:51.247 : #################### Trainning Resumed ####################
22-01-07 15:08:32.451 : 

22-01-07 15:08:32.451 : #################### Trainning Resumed ####################
22-01-07 15:08:32.856 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:08:42.673 : ===>Input:[4,3,164,220] output:[4,3,656,880]
22-01-07 15:09:57.940 : 

22-01-07 15:09:57.940 : #################### Trainning Resumed ####################
22-01-07 15:09:58.385 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:10:08.249 : ===>Input:[4,3,228,256] output:[4,3,912,1024]
22-01-07 15:14:41.250 : 

22-01-07 15:14:41.250 : #################### Trainning Resumed ####################
22-01-07 15:14:41.307 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 15:14:51.253 : ===>Input:[4,3,172,248] output:[4,3,688,992]
22-01-07 15:14:51.370 :        DEVICE ID : cuda
22-01-07 15:14:57.744 : L1 loss function
22-01-07 15:14:57.747 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:15:44.578 : 

22-01-07 15:15:44.579 : #################### Trainning Resumed ####################
22-01-07 15:15:44.875 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:16:02.757 : ===>Input:[8,3,256,256] output:[8,3,1024,1024]
22-01-07 15:16:02.871 :        DEVICE ID : cuda
22-01-07 15:16:09.184 : L1 loss function
22-01-07 15:16:09.185 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:17:14.871 : 

22-01-07 15:17:14.871 : #################### Trainning Resumed ####################
22-01-07 15:17:15.416 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:17:41.800 : ===>Input:[8,3,200,200] output:[8,3,800,800]
22-01-07 15:17:41.903 :        DEVICE ID : cuda
22-01-07 15:17:47.973 : L1 loss function
22-01-07 15:17:47.974 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:19:54.463 : 

22-01-07 15:19:54.463 : #################### Trainning Resumed ####################
22-01-07 15:19:54.926 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:20:23.988 : ===>Input:[8,3,210,210] output:[8,3,840,840]
22-01-07 15:20:24.223 :        DEVICE ID : cuda
22-01-07 15:20:28.704 : L1 loss function
22-01-07 15:20:28.744 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:21:27.409 : 

22-01-07 15:21:27.410 : #################### Trainning Resumed ####################
22-01-07 15:21:28.000 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:21:46.573 : ===>Input:[8,3,200,200] output:[8,3,800,800]
22-01-07 15:21:46.684 :        DEVICE ID : cuda
22-01-07 15:21:52.869 : L1 loss function
22-01-07 15:21:52.871 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:26:20.359 : 

22-01-07 15:26:20.359 : #################### Trainning Resumed ####################
22-01-07 15:26:21.008 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:26:45.455 : ===>Input:[8,3,200,200] output:[8,3,800,800]
22-01-07 15:26:45.578 :        DEVICE ID : cuda
22-01-07 15:26:51.803 : L1 loss function
22-01-07 15:26:51.805 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:28:39.099 : 

22-01-07 15:28:39.099 : #################### Trainning Resumed ####################
22-01-07 15:28:39.660 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:28:59.283 : ===>Input:[8,3,200,200] output:[8,3,800,800]
22-01-07 15:28:59.397 :        DEVICE ID : cuda
22-01-07 15:29:05.476 : L1 loss function
22-01-07 15:29:05.478 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:29:51.573 : 

22-01-07 15:29:51.573 : #################### Trainning Resumed ####################
22-01-07 15:29:52.135 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:30:14.930 : ===>Input:[8,3,190,190] output:[8,3,760,760]
22-01-07 15:30:15.081 :        DEVICE ID : cuda
22-01-07 15:30:18.445 : L1 loss function
22-01-07 15:30:18.448 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:31:49.047 : 

22-01-07 15:31:49.048 : #################### Trainning Resumed ####################
22-01-07 15:31:49.620 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:32:13.265 : ===>Input:[8,3,198,198] output:[8,3,792,792]
22-01-07 15:32:13.377 :        DEVICE ID : cuda
22-01-07 15:32:19.113 : L1 loss function
22-01-07 15:32:19.115 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:33:33.834 : 

22-01-07 15:33:33.836 : #################### Trainning Resumed ####################
22-01-07 15:33:34.515 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:33:55.492 : ===>Input:[8,3,190,190] output:[8,3,760,760]
22-01-07 15:33:55.605 :        DEVICE ID : cuda
22-01-07 15:34:01.566 : L1 loss function
22-01-07 15:34:01.567 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:35:43.870 : 

22-01-07 15:35:43.871 : #################### Trainning Resumed ####################
22-01-07 15:35:44.453 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:36:08.977 : 

22-01-07 15:36:08.977 : #################### Trainning Resumed ####################
22-01-07 15:36:09.101 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:36:41.031 : ===>Input:[8,3,192,152] output:[8,3,768,608]
22-01-07 15:36:41.175 :        DEVICE ID : cuda
22-01-07 15:36:49.477 : L1 loss function
22-01-07 15:36:49.478 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:39:33.992 : 

22-01-07 15:39:33.992 : #################### Trainning Resumed ####################
22-01-07 15:39:34.451 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:39:49.194 : ===>Input:[8,3,200,144] output:[8,3,800,576]
22-01-07 15:39:49.271 :        DEVICE ID : cuda
22-01-07 15:39:56.085 : L1 loss function
22-01-07 15:39:56.086 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:46:14.710 : 

22-01-07 15:46:14.710 : #################### Trainning Resumed ####################
22-01-07 15:46:15.320 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:46:39.904 : ===>Input:[8,3,248,132] output:[8,3,992,528]
22-01-07 15:46:39.981 :        DEVICE ID : cuda
22-01-07 15:46:47.522 : L1 loss function
22-01-07 15:46:47.523 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:47:23.976 : 

22-01-07 15:47:23.977 : #################### Trainning Resumed ####################
22-01-07 15:47:24.493 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:47:39.899 : ===>Input:[8,3,190,190] output:[8,3,760,760]
22-01-07 15:47:39.973 :        DEVICE ID : cuda
22-01-07 15:47:44.950 : L1 loss function
22-01-07 15:47:44.951 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 15:48:53.482 : 

22-01-07 15:48:53.482 : #################### Trainning Resumed ####################
22-01-07 15:48:53.846 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 15:49:04.736 : ===>Input:[8,3,168,136] output:[8,3,672,544]
22-01-07 15:49:04.841 :        DEVICE ID : cuda
22-01-07 15:49:10.498 : L1 loss function
22-01-07 15:49:10.499 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 16:22:39.788 : ===> Epoch[0]: Loss_l1: 0.05305  Duration: 33.488385 min
22-01-07 16:30:32.923 : ===> Valid. psnr: 25.5959, ssim: 0.6634, loss: 0.0394
22-01-07 16:30:33.166 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_0.pth
22-01-07 16:30:33.166 : 

22-01-07 16:30:33.167 : ===> TrainEpoch =1  lr = 0.0001
22-01-07 17:07:39.227 : ===> Epoch[1]: Loss_l1: 0.03931  Duration: 37.101483 min
22-01-07 17:15:31.087 : ===> Valid. psnr: 26.2568, ssim: 0.6796, loss: 0.0372
22-01-07 17:15:31.237 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_1.pth
22-01-07 17:15:31.237 : 

22-01-07 17:15:31.239 : ===> TrainEpoch =2  lr = 0.0001
22-01-07 17:54:31.578 : ===> Epoch[2]: Loss_l1: 0.03797  Duration: 39.005496 min
22-01-07 18:02:52.391 : ===> Valid. psnr: 26.3239, ssim: 0.6830, loss: 0.0372
22-01-07 18:02:52.566 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_2.pth
22-01-07 18:02:52.566 : 

22-01-07 18:11:04.526 : 

22-01-07 18:11:04.526 : #################### Trainning Resumed ####################
22-01-07 18:11:04.954 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 18:11:16.556 : ===>Input:[8,3,176,160] output:[8,3,704,640]
22-01-07 18:11:16.657 :        DEVICE ID : cuda
22-01-07 18:11:24.206 : L1 loss function
22-01-07 18:11:24.372 : ===> TrainEpoch =3  lr = 0.0001
22-01-07 18:51:15.955 : ===> Epoch[3]: Loss_l1: 0.03807  Duration: 39.860792 min
22-01-07 18:59:43.131 : ===> Valid. psnr: 26.6043, ssim: 0.6850, loss: 0.0364
22-01-07 18:59:43.282 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_3.pth
22-01-07 18:59:43.282 : 

22-01-07 18:59:43.283 : ===> TrainEpoch =4  lr = 0.0001
22-01-07 19:00:32.353 : 

22-01-07 19:00:32.353 : #################### Trainning Resumed ####################
22-01-07 19:00:32.581 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:00:35.678 : ===>Input:[4,3,166,180] output:[4,3,498,540]
22-01-07 19:01:30.665 : 

22-01-07 19:01:30.665 : #################### Trainning Resumed ####################
22-01-07 19:01:30.725 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:01:36.480 : ===>Input:[4,3,202,166] output:[4,3,606,498]
22-01-07 19:03:01.341 : 

22-01-07 19:03:01.341 : #################### Trainning Resumed ####################
22-01-07 19:03:01.432 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:03:05.168 : ===>Input:[4,3,146,148] output:[4,3,438,444]
22-01-07 19:05:59.857 : 

22-01-07 19:05:59.857 : #################### Trainning Resumed ####################
22-01-07 19:05:59.912 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:06:06.254 : ===>Input:[4,3,200,168] output:[4,3,600,504]
22-01-07 19:06:34.801 : 

22-01-07 19:06:34.801 : #################### Trainning Resumed ####################
22-01-07 19:06:34.863 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:06:41.336 : ===>Input:[4,3,148,194] output:[4,3,444,582]
22-01-07 19:07:19.755 : 

22-01-07 19:07:19.755 : #################### Trainning Resumed ####################
22-01-07 19:07:19.817 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:07:24.789 : ===>Input:[4,3,128,204] output:[4,3,384,612]
22-01-07 19:08:16.817 : 

22-01-07 19:08:16.817 : #################### Trainning Resumed ####################
22-01-07 19:08:16.876 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:08:23.265 : ===>Input:[4,3,226,146] output:[4,3,678,438]
22-01-07 19:37:42.682 : 

22-01-07 19:37:42.682 : #################### Trainning Resumed ####################
22-01-07 19:37:42.768 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:37:50.794 : ===>Input:[4,3,128,208] output:[4,3,384,624]
22-01-07 19:37:50.870 :        DEVICE ID : cuda
22-01-07 19:37:58.755 : L1 loss function
22-01-07 19:37:58.758 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:39:18.163 : 

22-01-07 19:39:18.163 : #################### Trainning Resumed ####################
22-01-07 19:39:18.631 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:39:21.949 : ===>Input:[4,3,148,174] output:[4,3,444,522]
22-01-07 19:39:22.011 :        DEVICE ID : cuda
22-01-07 19:39:25.544 : L1 loss function
22-01-07 19:39:25.545 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:40:27.946 : 

22-01-07 19:40:27.946 : #################### Trainning Resumed ####################
22-01-07 19:40:28.151 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:40:32.144 : ===>Input:[4,3,138,212] output:[4,3,414,636]
22-01-07 19:40:32.208 :        DEVICE ID : cuda
22-01-07 19:40:35.841 : L1 loss function
22-01-07 19:40:35.843 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:41:00.294 : 

22-01-07 19:41:00.294 : #################### Trainning Resumed ####################
22-01-07 19:41:00.541 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:41:05.505 : ===>Input:[4,3,180,154] output:[4,3,540,462]
22-01-07 19:41:05.564 :        DEVICE ID : cuda
22-01-07 19:41:09.185 : L1 loss function
22-01-07 19:41:09.186 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:41:29.320 : 

22-01-07 19:41:29.320 : #################### Trainning Resumed ####################
22-01-07 19:41:29.376 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:41:35.710 : ===>Input:[4,3,202,156] output:[4,3,606,468]
22-01-07 19:41:35.782 :        DEVICE ID : cuda
22-01-07 19:41:39.608 : L1 loss function
22-01-07 19:41:39.609 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:43:27.908 : 

22-01-07 19:43:27.909 : #################### Trainning Resumed ####################
22-01-07 19:43:28.107 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:43:30.994 : ===>Input:[4,3,190,190] output:[4,3,570,570]
22-01-07 19:43:31.051 :        DEVICE ID : cuda
22-01-07 19:43:34.655 : L1 loss function
22-01-07 19:43:34.656 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:44:00.392 : 

22-01-07 19:44:00.393 : #################### Trainning Resumed ####################
22-01-07 19:44:00.781 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:44:05.984 : ===>Input:[4,3,220,220] output:[4,3,660,660]
22-01-07 19:44:06.043 :        DEVICE ID : cuda
22-01-07 19:44:09.652 : L1 loss function
22-01-07 19:44:09.653 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:44:32.679 : 

22-01-07 19:44:32.679 : #################### Trainning Resumed ####################
22-01-07 19:44:32.869 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:4
22-01-07 19:44:36.719 : ===>Input:[4,3,240,240] output:[4,3,720,720]
22-01-07 19:44:36.779 :        DEVICE ID : cuda
22-01-07 19:44:40.304 : L1 loss function
22-01-07 19:44:40.305 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:45:36.338 : 

22-01-07 19:45:36.339 : #################### Trainning Resumed ####################
22-01-07 19:45:36.650 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 19:45:46.659 : ===>Input:[8,3,190,190] output:[8,3,570,570]
22-01-07 19:45:46.719 :        DEVICE ID : cuda
22-01-07 19:45:50.288 : L1 loss function
22-01-07 19:45:50.289 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:46:15.537 : 

22-01-07 19:46:15.537 : #################### Trainning Resumed ####################
22-01-07 19:46:15.770 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 19:46:26.457 : ===>Input:[8,3,180,180] output:[8,3,540,540]
22-01-07 19:46:26.516 :        DEVICE ID : cuda
22-01-07 19:46:30.162 : L1 loss function
22-01-07 19:46:30.163 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:47:05.641 : 

22-01-07 19:47:05.641 : #################### Trainning Resumed ####################
22-01-07 19:47:05.732 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 19:47:16.507 : ===>Input:[8,3,170,170] output:[8,3,510,510]
22-01-07 19:47:16.568 :        DEVICE ID : cuda
22-01-07 19:47:20.046 : L1 loss function
22-01-07 19:47:20.047 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 19:48:06.966 : 

22-01-07 19:48:06.968 : #################### Trainning Resumed ####################
22-01-07 19:48:07.576 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 19:48:15.003 : ===>Input:[8,3,146,132] output:[8,3,438,396]
22-01-07 19:48:15.083 :        DEVICE ID : cuda
22-01-07 19:48:21.732 : L1 loss function
22-01-07 19:48:21.733 : ===> TrainEpoch =0  lr = 0.0001
22-01-07 20:23:15.855 : ===> Epoch[0]: Loss_l1: 0.05622  Duration: 34.900663 min
22-01-07 20:29:50.442 : ===> Valid. psnr: 25.8596, ssim: 0.6656, loss: 0.0399
22-01-07 20:29:50.696 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_0.pth
22-01-07 20:29:50.697 : 

22-01-07 20:29:50.698 : ===> TrainEpoch =1  lr = 0.0001
22-01-07 21:04:26.748 : ===> Epoch[1]: Loss_l1: 0.03828  Duration: 34.601477 min
22-01-07 21:10:50.419 : ===> Valid. psnr: 26.7811, ssim: 0.6925, loss: 0.0362
22-01-07 21:10:50.536 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_1.pth
22-01-07 21:10:50.536 : 

22-01-07 21:12:29.433 : 

22-01-07 21:12:29.433 : #################### Trainning Resumed ####################
22-01-07 21:12:29.704 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-07 21:12:51.180 : ===>Input:[8,3,162,152] output:[8,3,486,456]
22-01-07 21:12:51.267 :        DEVICE ID : cuda
22-01-07 21:12:58.749 : L1 loss function
22-01-07 21:12:58.964 : ===> TrainEpoch =2  lr = 0.0001
22-01-07 21:52:30.197 : ===> Epoch[2]: Loss_l1: 0.03646  Duration: 39.520942 min
22-01-07 22:00:07.779 : ===> Valid. psnr: 27.0063, ssim: 0.7088, loss: 0.0353
22-01-07 22:00:07.956 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_2.pth
22-01-07 22:00:07.956 : 

22-01-08 10:11:43.877 : 

22-01-08 10:11:43.877 : #################### Trainning Resumed ####################
22-01-08 10:11:44.572 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 10:12:12.444 : ===>Input:[8,3,164,128] output:[8,3,492,384]
22-01-08 10:12:12.590 :        DEVICE ID : cuda
22-01-08 10:12:20.754 : L1 loss function
22-01-08 10:12:20.908 : ===> TrainEpoch =3  lr = 0.0001
22-01-08 10:49:49.875 : ===> Epoch[3]: Loss_l1: 0.03544  Duration: 37.485433 min
22-01-08 10:57:14.256 : ===> Valid. psnr: 27.1956, ssim: 0.7086, loss: 0.0346
22-01-08 10:57:14.509 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_3.pth
22-01-08 10:57:14.509 : 

22-01-08 10:57:14.515 : ===> TrainEpoch =4  lr = 0.0001
22-01-08 11:41:46.009 : 

22-01-08 11:41:46.010 : #################### Trainning Resumed ####################
22-01-08 11:41:46.592 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 11:41:53.604 : 

22-01-08 11:41:53.604 : #################### Trainning Resumed ####################
22-01-08 11:41:53.662 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 11:42:01.811 : ===>Input:[8,3,138,176] output:[8,3,414,528]
22-01-08 11:42:01.889 :        DEVICE ID : cuda
22-01-08 11:42:12.657 : L1 loss function
22-01-08 11:42:12.789 : ===> TrainEpoch =4  lr = 0.0001
22-01-08 12:25:23.248 : ===> Epoch[4]: Loss_l1: 0.03422  Duration: 43.175821 min
22-01-08 12:32:05.478 : ===> Valid. psnr: 27.6483, ssim: 0.7176, loss: 0.0326
22-01-08 12:32:05.647 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_4.pth
22-01-08 12:32:05.647 : 

22-01-08 12:32:05.648 : ===> TrainEpoch =5  lr = 0.0001
22-01-08 13:17:43.770 : ===> Epoch[5]: Loss_l1: 0.03371  Duration: 45.635958 min
22-01-08 13:26:47.948 : ===> Valid. psnr: 27.5755, ssim: 0.7210, loss: 0.0332
22-01-08 13:26:48.158 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_5.pth
22-01-08 13:26:48.158 : 

22-01-08 13:35:33.374 : 

22-01-08 13:35:33.375 : #################### Trainning Resumed ####################
22-01-08 13:35:33.885 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 13:35:46.861 : ===>Input:[8,3,170,170] output:[8,3,510,510]
22-01-08 13:35:46.942 :        DEVICE ID : cuda
22-01-08 13:35:54.688 : L1 loss function
22-01-08 13:35:54.689 : ===> TrainEpoch =0  lr = 0.0001
22-01-08 13:36:30.192 : 

22-01-08 13:36:30.194 : #################### Trainning Resumed ####################
22-01-08 13:36:30.655 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 13:36:41.270 : ===>Input:[8,3,170,180] output:[8,3,510,540]
22-01-08 13:36:41.349 :        DEVICE ID : cuda
22-01-08 13:36:46.601 : L1 loss function
22-01-08 13:36:46.602 : ===> TrainEpoch =0  lr = 0.0001
22-01-08 13:37:24.980 : 

22-01-08 13:37:24.980 : #################### Trainning Resumed ####################
22-01-08 13:37:25.440 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 13:37:32.942 : ===>Input:[8,3,130,172] output:[8,3,390,516]
22-01-08 13:37:33.008 :        DEVICE ID : cuda
22-01-08 13:37:36.918 : L1 loss function
22-01-08 13:37:36.919 : ===> TrainEpoch =0  lr = 0.0001
22-01-08 13:51:39.225 : 

22-01-08 13:51:39.225 : #################### Trainning Resumed ####################
22-01-08 13:51:39.755 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 13:51:52.132 : ===>Input:[8,3,144,178] output:[8,3,432,534]
22-01-08 13:51:52.233 :        DEVICE ID : cuda
22-01-08 13:51:59.440 : L1 loss function
22-01-08 13:51:59.441 : ===> TrainEpoch =0  lr = 0.0001
22-01-08 14:35:50.952 : ===> Epoch[0]: Loss_l1: 0.05520  Duration: 43.857221 min
22-01-08 14:43:54.591 : ===> Valid. psnr: 26.0440, ssim: 0.6674, loss: 0.0392
22-01-08 14:43:55.031 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_0.pth
22-01-08 14:43:55.031 : 

22-01-08 14:43:55.037 : ===> TrainEpoch =1  lr = 0.0001
22-01-08 15:25:54.418 : ===> Epoch[1]: Loss_l1: 0.03837  Duration: 41.990908 min
22-01-08 15:32:30.097 : ===> Valid. psnr: 26.7365, ssim: 0.6886, loss: 0.0366
22-01-08 15:32:30.293 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_1.pth
22-01-08 15:32:30.294 : 

22-01-08 15:43:07.236 : 

22-01-08 15:43:07.236 : #################### Trainning Resumed ####################
22-01-08 15:43:07.495 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 15:43:17.453 : ===>Input:[8,3,142,172] output:[8,3,426,516]
22-01-08 15:43:17.538 :        DEVICE ID : cuda
22-01-08 15:43:25.141 : L1 loss function
22-01-08 15:43:25.195 : ===> TrainEpoch =2  lr = 0.0001
22-01-08 16:20:08.492 : ===> Epoch[2]: Loss_l1: 0.03691  Duration: 36.720717 min
22-01-08 16:26:55.768 : ===> Valid. psnr: 27.1986, ssim: 0.7019, loss: 0.0345
22-01-08 16:26:55.966 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_2.pth
22-01-08 16:26:55.966 : 

22-01-08 16:26:55.971 : ===> TrainEpoch =3  lr = 0.0001
22-01-08 17:03:08.445 : ===> Epoch[3]: Loss_l1: 0.03553  Duration: 36.207533 min
22-01-08 17:09:38.807 : ===> Valid. psnr: 27.4177, ssim: 0.7127, loss: 0.0337
22-01-08 17:09:38.921 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_3.pth
22-01-08 17:09:38.921 : 

22-01-08 17:09:38.921 : ===> TrainEpoch =4  lr = 0.0001
22-01-08 17:44:31.356 : ===> Epoch[4]: Loss_l1: 0.03486  Duration: 34.877383 min
22-01-08 17:51:07.814 : ===> Valid. psnr: 27.7178, ssim: 0.7190, loss: 0.0328
22-01-08 17:51:07.965 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_4.pth
22-01-08 17:51:07.965 : 

22-01-08 17:51:07.966 : ===> TrainEpoch =5  lr = 0.0001
22-01-08 18:28:03.397 : ===> Epoch[5]: Loss_l1: 0.03403  Duration: 36.922950 min
22-01-08 18:34:53.666 : ===> Valid. psnr: 27.5534, ssim: 0.7158, loss: 0.0334
22-01-08 18:34:53.797 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_5.pth
22-01-08 18:34:53.797 : 

22-01-08 18:34:53.798 : ===> TrainEpoch =6  lr = 0.0001
22-01-08 19:09:56.043 : ===> Epoch[6]: Loss_l1: 0.03371  Duration: 35.038367 min
22-01-08 19:16:29.171 : ===> Valid. psnr: 27.6563, ssim: 0.7208, loss: 0.0327
22-01-08 19:16:29.231 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_6.pth
22-01-08 19:16:29.231 : 

22-01-08 19:22:12.757 : 

22-01-08 19:22:12.757 : #################### Trainning Resumed ####################
22-01-08 19:22:13.018 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 19:22:19.781 : ===>Input:[8,3,134,140] output:[8,3,402,420]
22-01-08 19:22:19.868 :        DEVICE ID : cuda
22-01-08 19:22:27.366 : L1 loss function
22-01-08 19:22:27.421 : ===> TrainEpoch =7  lr = 1e-05
22-01-08 20:02:42.052 : ===> Epoch[7]: Loss_l1: 0.03263  Duration: 40.244492 min
22-01-08 20:10:14.060 : ===> Valid. psnr: 28.1244, ssim: 0.7290, loss: 0.0312
22-01-08 20:10:14.182 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_7.pth
22-01-08 20:10:14.182 : 

22-01-08 20:11:42.210 : 

22-01-08 20:11:42.210 : #################### Trainning Resumed ####################
22-01-08 20:11:42.512 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-08 20:11:52.190 : ===>Input:[8,3,192,138] output:[8,3,576,414]
22-01-08 20:11:52.269 :        DEVICE ID : cuda
22-01-08 20:12:00.122 : L1 loss function
22-01-08 20:12:00.174 : ===> TrainEpoch =8  lr = 1e-05
22-01-08 20:48:26.550 : ===> Epoch[8]: Loss_l1: 0.03241  Duration: 36.439496 min
22-01-08 20:55:23.947 : ===> Valid. psnr: 27.9998, ssim: 0.7261, loss: 0.0316
22-01-08 20:55:24.031 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_8.pth
22-01-08 20:55:24.031 : 


22-01-09 11:48:54.424 : 

22-01-09 11:48:54.425 : #################### Trainning Resumed ####################
22-01-09 11:48:55.141 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 11:49:02.981 : ===>Input:[8,3,142,132] output:[8,3,568,528]
22-01-09 11:49:03.077 :        DEVICE ID : cuda
22-01-09 11:49:10.762 : L1 loss function
22-01-09 11:52:34.871 : 

22-01-09 11:52:34.871 : #################### Trainning Resumed ####################
22-01-09 11:52:35.248 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 11:52:43.781 : ===>Input:[8,3,186,128] output:[8,3,558,384]
22-01-09 11:52:43.839 :        DEVICE ID : cuda
22-01-09 11:52:47.957 : L1 loss function
22-01-09 11:52:48.023 : ===> TrainEpoch =9  lr = 1e-05
22-01-09 12:31:41.411 : ===> Epoch[9]: Loss_l1: 0.03225  Duration: 38.889562 min
22-01-09 12:38:37.780 : ===> Valid. psnr: 28.0793, ssim: 0.7284, loss: 0.0314
22-01-09 12:38:37.944 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_9.pth
22-01-09 12:38:37.944 : 


22-01-09 15:26:39.440 : #################### Trainning Resumed ####################
22-01-09 15:26:39.976 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 15:26:54.576 : ===>Input:[8,3,152,168] output:[8,3,456,504]
22-01-09 15:26:54.658 :        DEVICE ID : cuda
22-01-09 15:27:02.263 : L1 loss function
22-01-09 15:27:02.403 : ===> TrainEpoch =10  lr = 1e-05
22-01-09 16:20:48.607 : 

22-01-09 16:20:48.608 : #################### Trainning Resumed ####################
22-01-09 16:20:48.869 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 16:21:02.537 : ===>Input:[8,3,176,140] output:[8,3,528,420]
22-01-09 16:21:02.611 :        DEVICE ID : cuda
22-01-09 16:21:10.249 : L1 loss function
22-01-09 16:21:10.415 : ===> TrainEpoch =11  lr = 1e-05
22-01-09 17:03:57.480 : ===> Epoch[11]: Loss_l1: 0.03232  Duration: 42.785271 min
22-01-09 17:11:33.858 : ===> Valid. psnr: 28.0840, ssim: 0.7275, loss: 0.0317
22-01-09 17:11:34.019 : ===> Checkpoint saved to checkpoints/enhance_net_checkpoints/checkpoint_base_epoch_11.pth
22-01-09 17:11:34.019 : 

22-01-09 17:11:34.019 : ===> TrainEpoch =12  lr = 1e-05
22-01-09 23:04:51.212 : 

22-01-09 23:04:51.212 : #################### Trainning Resumed ####################
22-01-09 23:04:51.955 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 23:05:14.273 : ===>Input:[8,3,240,240] output:[8,3,960,960]
22-01-09 23:06:13.905 : 

22-01-09 23:06:13.905 : #################### Trainning Resumed ####################
22-01-09 23:06:14.496 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 23:06:30.130 : ===>Input:[8,3,240,240] output:[8,3,960,960]
22-01-09 23:06:30.213 :        DEVICE ID : cuda
22-01-09 23:06:40.982 : L1 loss function
22-01-09 23:06:40.983 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 23:07:57.406 : 

22-01-09 23:07:57.406 : #################### Trainning Resumed ####################
22-01-09 23:07:57.722 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 23:08:14.151 : ===>Input:[8,3,240,240] output:[8,3,960,960]
22-01-09 23:08:14.234 :        DEVICE ID : cuda
22-01-09 23:08:21.069 : L1 loss function
22-01-09 23:08:21.070 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 23:11:17.085 : 

22-01-09 23:11:17.085 : #################### Trainning Resumed ####################
22-01-09 23:11:17.579 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 23:11:35.404 : ===>Input:[8,3,240,240] output:[8,3,960,960]
22-01-09 23:11:35.489 :        DEVICE ID : cuda
22-01-09 23:11:42.017 : L1 loss function
22-01-09 23:11:42.019 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 23:14:47.847 : 

22-01-09 23:14:47.847 : #################### Trainning Resumed ####################
22-01-09 23:15:28.641 : 

22-01-09 23:15:28.641 : #################### Trainning Resumed ####################
22-01-09 23:15:29.064 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 23:15:51.370 : ===>Input:[8,3,240,240] output:[8,3,960,960]
22-01-09 23:15:51.548 :        DEVICE ID : cuda
22-01-09 23:15:58.585 : L1 loss function
22-01-09 23:15:58.587 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 23:18:54.450 : 

22-01-09 23:18:54.450 : #################### Trainning Resumed ####################
22-01-09 23:18:55.060 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 23:19:11.025 : ===>Input:[8,3,240,240] output:[8,3,720,720]
22-01-09 23:19:11.117 :        DEVICE ID : cuda
22-01-09 23:19:18.471 : L1 loss function
22-01-09 23:19:18.472 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 23:20:26.724 : 

22-01-09 23:20:26.725 : #################### Trainning Resumed ####################
22-01-09 23:20:27.214 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:16
22-01-09 23:21:17.482 : ===>Input:[16,3,256,256] output:[16,3,768,768]
22-01-09 23:21:17.746 :        DEVICE ID : cuda
22-01-09 23:21:26.015 : L1 loss function
22-01-09 23:21:26.029 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 23:23:27.899 : 

22-01-09 23:23:27.899 : #################### Trainning Resumed ####################
22-01-09 23:23:28.521 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 23:23:45.595 : ===>Input:[8,3,330,330] output:[8,3,990,990]
22-01-09 23:23:45.715 :        DEVICE ID : cuda
22-01-09 23:23:53.313 : L1 loss function
22-01-09 23:23:53.314 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 23:24:30.288 : 

22-01-09 23:24:30.288 : #################### Trainning Resumed ####################
22-01-09 23:24:30.870 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 23:24:50.356 : ===>Input:[8,3,334,334] output:[8,3,1002,1002]
22-01-09 23:24:50.450 :        DEVICE ID : cuda
22-01-09 23:24:56.198 : L1 loss function
22-01-09 23:24:56.199 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 23:26:15.384 : 

22-01-09 23:26:15.384 : #################### Trainning Resumed ####################
22-01-09 23:26:15.981 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
22-01-09 23:26:38.027 : ===>Input:[8,3,336,336] output:[8,3,1008,1008]
22-01-09 23:26:38.119 :        DEVICE ID : cuda
22-01-09 23:26:43.928 : L1 loss function
22-01-09 23:26:43.929 : ===> TrainEpoch =0  lr = 0.0001
22-01-09 23:28:40.350 : 

22-01-09 23:28:40.351 : #################### Trainning Resumed ####################
22-01-09 23:28:40.904 : ===>Trainning Data:[ Train:6282  Valid:1282] Batch:8
