
21-12-31 18:08:15.424 : #################### Trainning Resumed ####################
21-12-31 18:08:15.424 : scale4
21-12-31 18:08:15.566 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 18:08:24.231 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 18:08:24.297 :        DEVICE ID : cuda
21-12-31 18:08:27.284 : L1 loss function
21-12-31 18:08:27.371 : ===> TrainEpoch =0  lr = 0.0001
21-12-31 18:09:33.682 : 

21-12-31 18:09:33.682 : #################### Trainning Resumed ####################
21-12-31 18:09:33.682 : scale4
21-12-31 18:09:34.086 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 18:09:43.609 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 18:09:43.671 :        DEVICE ID : cuda
21-12-31 18:09:46.460 : L1 loss function
21-12-31 18:09:46.535 : ===> TrainEpoch =0  lr = 0.0001
21-12-31 18:29:22.538 : ===> Epoch[0]: Loss_l1: 0.09311  Duration: 19.599748 min
21-12-31 18:31:23.373 : ===> Valid. psnr: 19.1811, ssim: 0.5902, loss: 0.0809
21-12-31 18:31:23.424 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_0.pth
21-12-31 18:31:23.424 : 

21-12-31 18:31:23.425 : ===> TrainEpoch =1  lr = 0.0001
21-12-31 18:50:39.106 : ===> Epoch[1]: Loss_l1: 0.07980  Duration: 19.261392 min
21-12-31 18:52:40.603 : ===> Valid. psnr: 19.4050, ssim: 0.6097, loss: 0.0777
21-12-31 18:52:40.634 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_1.pth
21-12-31 18:52:40.634 : 

21-12-31 18:54:32.386 : 

21-12-31 18:54:32.386 : #################### Trainning Resumed ####################
21-12-31 18:54:32.386 : scale4
21-12-31 18:54:32.481 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 18:54:41.463 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 18:54:41.567 :        DEVICE ID : cuda
21-12-31 18:54:48.082 : L1 loss function
21-12-31 18:54:48.154 : ===> TrainEpoch =2  lr = 0.0001
21-12-31 18:58:14.815 : 

21-12-31 18:58:14.815 : #################### Trainning Resumed ####################
21-12-31 18:58:14.815 : scale4
21-12-31 18:58:15.201 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 18:58:27.241 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 18:58:27.310 :        DEVICE ID : cuda
21-12-31 18:58:30.425 : L1 loss function
21-12-31 18:58:30.493 : ===> TrainEpoch =0  lr = 0.0001
21-12-31 19:00:03.552 : 

21-12-31 19:00:03.553 : #################### Trainning Resumed ####################
21-12-31 19:00:03.553 : scale4
21-12-31 19:00:03.743 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 19:00:12.405 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 19:00:12.465 :        DEVICE ID : cuda
21-12-31 19:00:15.310 : L1 loss function
21-12-31 19:00:15.380 : ===> TrainEpoch =0  lr = 0.0001
21-12-31 19:00:22.910 : 

21-12-31 19:00:22.910 : #################### Trainning Resumed ####################
21-12-31 19:00:22.910 : scale4
21-12-31 19:00:22.955 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 19:00:33.304 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 19:00:33.370 :        DEVICE ID : cuda
21-12-31 19:00:36.118 : L1 loss function
21-12-31 19:00:36.153 : ===> TrainEpoch =0  lr = 1e-05
21-12-31 19:20:13.100 : ===> Epoch[0]: Loss_l1: 0.27155  Duration: 19.616492 min
21-12-31 19:22:11.952 : ===> Valid. psnr: 11.3582, ssim: 0.3377, loss: 0.2294
21-12-31 19:22:12.014 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_0.pth
21-12-31 19:22:12.014 : 

21-12-31 19:22:12.015 : ===> TrainEpoch =1  lr = 1e-05
21-12-31 19:41:23.289 : ===> Epoch[1]: Loss_l1: 0.22917  Duration: 19.188838 min
21-12-31 19:43:26.759 : ===> Valid. psnr: 11.3670, ssim: 0.3410, loss: 0.2290
21-12-31 19:43:26.805 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_1.pth
21-12-31 19:43:26.805 : 

21-12-31 19:43:26.806 : ===> TrainEpoch =2  lr = 1e-05
21-12-31 19:46:27.957 : 

21-12-31 19:46:27.957 : #################### Trainning Resumed ####################
21-12-31 19:46:27.957 : scale4
21-12-31 19:46:28.053 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 19:46:41.763 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 19:46:41.858 :        DEVICE ID : cuda
21-12-31 19:46:48.356 : L1 loss function
21-12-31 19:46:48.426 : ===> TrainEpoch =0  lr = 0.0001
21-12-31 20:01:17.860 : 

21-12-31 20:01:17.861 : #################### Trainning Resumed ####################
21-12-31 20:01:17.861 : scale4
21-12-31 20:01:17.964 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 20:01:28.951 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 20:01:29.054 :        DEVICE ID : cuda
21-12-31 20:01:55.350 : 

21-12-31 20:01:55.351 : #################### Trainning Resumed ####################
21-12-31 20:01:55.351 : scale4
21-12-31 20:01:55.524 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 20:02:06.372 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 20:02:06.436 :        DEVICE ID : cuda
21-12-31 20:02:29.942 : 

21-12-31 20:02:29.942 : #################### Trainning Resumed ####################
21-12-31 20:02:29.942 : scale1
21-12-31 20:02:30.061 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 20:02:39.121 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 20:02:39.179 :        DEVICE ID : cuda
21-12-31 20:02:41.909 : L1 loss function
21-12-31 20:04:09.014 : 

21-12-31 20:04:09.014 : #################### Trainning Resumed ####################
21-12-31 20:04:09.014 : scale1
21-12-31 20:04:09.059 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 20:04:17.598 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 20:04:17.655 :        DEVICE ID : cuda
21-12-31 20:04:20.480 : L1 loss function
21-12-31 20:04:20.623 : ===> TrainEpoch =0  lr = 0.0001
21-12-31 20:06:22.094 : 

21-12-31 20:06:22.095 : #################### Trainning Resumed ####################
21-12-31 20:06:22.095 : scale1
21-12-31 20:06:22.148 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 20:06:31.338 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 20:06:31.396 :        DEVICE ID : cuda
21-12-31 20:06:34.304 : L1 loss function
21-12-31 20:06:34.439 : ===> TrainEpoch =0  lr = 0.0001
21-12-31 20:07:20.007 : 

21-12-31 20:07:20.008 : #################### Trainning Resumed ####################
21-12-31 20:07:20.008 : scale4
21-12-31 20:07:20.232 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 20:07:28.714 : ===>Input:[16,3,256,256] output:[16,3,1024,1024]
21-12-31 20:07:28.788 :        DEVICE ID : cuda
21-12-31 20:07:31.794 : L1 loss function
21-12-31 20:07:31.925 : ===> TrainEpoch =0  lr = 0.0001
21-12-31 20:10:20.754 : 

21-12-31 20:10:20.754 : #################### Trainning Resumed ####################
21-12-31 20:10:20.754 : scale1
21-12-31 20:10:33.174 : 

21-12-31 20:10:33.174 : #################### Trainning Resumed ####################
21-12-31 20:10:33.174 : scale1
21-12-31 20:10:35.339 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 20:10:46.162 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 20:10:46.261 :        DEVICE ID : cuda
21-12-31 20:10:58.278 : L1 loss function
21-12-31 20:10:58.406 : ===> TrainEpoch =0  lr = 1e-05
21-12-31 20:13:40.429 : 

21-12-31 20:13:40.429 : #################### Trainning Resumed ####################
21-12-31 20:13:40.429 : scale1
21-12-31 20:13:41.565 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 20:13:59.250 : 

21-12-31 20:13:59.250 : #################### Trainning Resumed ####################
21-12-31 20:13:59.250 : scale1
21-12-31 20:13:59.303 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 20:14:07.092 : ===>Input:[16,3,256,256] output:[16,3,256,256]
21-12-31 20:14:07.157 :        DEVICE ID : cuda
21-12-31 20:14:11.097 : L1 loss function
21-12-31 20:14:11.175 : ===> TrainEpoch =0  lr = 1e-05
21-12-31 20:15:01.449 : 

21-12-31 20:15:01.449 : #################### Trainning Resumed ####################
21-12-31 20:15:01.449 : scale4
21-12-31 20:15:01.496 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
21-12-31 20:15:10.616 : ===>Input:[16,3,256,256] output:[16,3,1024,1024]
21-12-31 20:15:10.693 :        DEVICE ID : cuda
21-12-31 20:15:21.280 : 

21-12-31 20:15:21.280 : #################### Trainning Resumed ####################
21-12-31 20:15:21.280 : scale4
21-12-31 20:15:21.329 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-31 20:15:24.008 : ===>Input:[4,3,256,256] output:[4,3,1024,1024]
21-12-31 20:15:24.075 :        DEVICE ID : cuda
21-12-31 20:15:26.874 : L1 loss function
21-12-31 20:15:26.911 : ===> TrainEpoch =13  lr = 1e-05
21-12-31 20:17:22.152 : 

21-12-31 20:17:22.152 : #################### Trainning Resumed ####################
21-12-31 20:17:22.152 : scale1
21-12-31 20:17:22.524 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:8
21-12-31 20:17:30.523 : ===>Input:[8,3,256,256] output:[8,3,256,256]
21-12-31 20:17:30.584 :        DEVICE ID : cuda
21-12-31 20:17:33.469 : L1 loss function
21-12-31 20:17:33.602 : ===> TrainEpoch =0  lr = 1e-05
21-12-31 20:18:12.268 : 

21-12-31 20:18:12.268 : #################### Trainning Resumed ####################
21-12-31 20:18:12.269 : scale1
21-12-31 20:18:12.315 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:6
21-12-31 20:18:17.106 : ===>Input:[6,3,256,256] output:[6,3,256,256]
21-12-31 20:18:17.163 :        DEVICE ID : cuda
21-12-31 20:18:19.959 : L1 loss function
21-12-31 20:18:20.024 : ===> TrainEpoch =0  lr = 1e-05
21-12-31 20:18:51.075 : 

21-12-31 20:18:51.075 : #################### Trainning Resumed ####################
21-12-31 20:18:51.075 : scale1
21-12-31 20:18:51.122 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-31 20:18:53.619 : ===>Input:[4,3,256,256] output:[4,3,256,256]
21-12-31 20:18:53.676 :        DEVICE ID : cuda
21-12-31 20:18:56.374 : L1 loss function
21-12-31 20:18:56.440 : ===> TrainEpoch =0  lr = 1e-05
21-12-31 20:20:12.308 : 

21-12-31 20:20:12.308 : #################### Trainning Resumed ####################
21-12-31 20:20:12.308 : scale1
21-12-31 20:20:12.633 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-31 20:20:15.532 : ===>Input:[4,3,256,256] output:[4,3,256,256]
21-12-31 20:20:15.588 :        DEVICE ID : cuda
21-12-31 20:20:18.447 : L1 loss function
21-12-31 20:20:18.509 : ===> TrainEpoch =0  lr = 1e-05
