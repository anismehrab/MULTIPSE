

21-12-28 09:43:29.199 : #################### Trainning Resumed ####################
21-12-28 09:43:29.200 : scale4
21-12-28 09:43:29.243 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-28 09:43:31.732 : ===>Input:[4,3,256,256] output:[4,3,1024,1024]
21-12-28 09:43:31.823 :        DEVICE ID : cuda
21-12-28 09:43:38.233 : L1 loss function
21-12-28 09:43:38.366 : ===> TrainEpoch =0  lr = 1e-05
21-12-28 11:44:27.115 : ===> Epoch[0]: Loss_l1: 0.07608  Duration: 120.817733 min
21-12-28 12:06:09.984 : ===> Valid. psnr: 21.5362, ssim: 0.7188, loss: 0.0436
21-12-28 12:06:10.083 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_0.pth
21-12-28 12:06:10.083 : 

21-12-28 12:06:10.085 : ===> TrainEpoch =1  lr = 1e-05
21-12-28 14:01:41.677 : ===> Epoch[1]: Loss_l1: 0.04227  Duration: 115.528425 min
21-12-28 14:23:53.715 : ===> Valid. psnr: 21.9442, ssim: 0.7517, loss: 0.0406
21-12-28 14:23:53.774 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_1.pth
21-12-28 14:23:53.775 : 

21-12-28 14:23:53.776 : ===> TrainEpoch =2  lr = 1e-05
21-12-28 16:28:29.105 : ===> Epoch[2]: Loss_l1: 0.03884  Duration: 124.588958 min
21-12-28 16:51:06.029 : ===> Valid. psnr: 22.9775, ssim: 0.7550, loss: 0.0328
21-12-28 16:51:06.064 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_2.pth
21-12-28 16:51:06.064 : 

21-12-28 20:04:02.547 : #################### Trainning Resumed ####################
21-12-28 20:04:02.547 : scale4
21-12-28 20:04:03.761 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-28 20:04:06.888 : ===>Input:[4,3,256,256] output:[4,3,1024,1024]
21-12-28 20:04:06.957 :        DEVICE ID : cuda
21-12-28 20:04:10.218 : L1 loss function
21-12-28 20:04:10.278 : ===> TrainEpoch =3  lr = 1e-05
21-12-28 22:00:52.401 : ===> Epoch[3]: Loss_l1: 0.03110  Duration: 116.702067 min
21-12-28 22:22:44.781 : ===> Valid. psnr: 23.3744, ssim: 0.7802, loss: 0.0300
21-12-28 22:22:44.833 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_3.pth
21-12-28 22:22:44.833 : 

21-12-29 09:24:03.501 : #################### Trainning Resumed ####################
21-12-29 09:24:03.501 : scale4
21-12-29 09:24:05.609 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-29 09:24:07.536 : ===>Input:[4,3,256,256] output:[4,3,1024,1024]
21-12-29 09:24:07.638 :        DEVICE ID : cuda
21-12-29 09:24:13.516 : L1 loss function
21-12-29 09:24:13.602 : ===> TrainEpoch =4  lr = 1e-05
21-12-29 18:40:28.260 : 

21-12-29 18:40:28.261 : #################### Trainning Resumed ####################
21-12-29 18:40:28.261 : scale4
21-12-29 18:40:31.045 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-29 18:40:33.615 : ===>Input:[4,3,256,256] output:[4,3,1024,1024]
21-12-29 18:40:33.712 :        DEVICE ID : cuda
21-12-29 18:40:43.284 : L1 loss function
21-12-29 18:40:43.356 : ===> TrainEpoch =6  lr = 1e-05
21-12-29 20:43:36.205 : ===> Epoch[6]: Loss_l1: 0.02795  Duration: 122.882608 min
21-12-29 21:05:15.120 : ===> Valid. psnr: 23.9967, ssim: 0.7982, loss: 0.0275
21-12-29 21:05:15.236 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_6.pth
21-12-29 21:05:15.236 : 

21-12-30 09:40:41.372 : #################### Trainning Resumed ####################
21-12-30 09:40:41.372 : scale4
21-12-30 09:40:43.503 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-30 09:40:45.791 : ===>Input:[4,3,256,256] output:[4,3,1024,1024]
21-12-30 09:40:45.889 :        DEVICE ID : cuda
21-12-30 09:40:55.088 : L1 loss function
21-12-30 09:40:55.184 : ===> TrainEpoch =7  lr = 1e-05
21-12-30 11:43:27.335 : ===> Epoch[7]: Loss_l1: 0.02721  Duration: 122.538467 min
21-12-30 12:06:24.613 : ===> Valid. psnr: 24.0057, ssim: 0.8028, loss: 0.0272
21-12-30 12:06:24.743 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_7.pth
21-12-30 12:06:24.744 : 

21-12-30 12:06:24.746 : ===> TrainEpoch =8  lr = 1e-05
21-12-30 14:11:01.016 : ===> Epoch[8]: Loss_l1: 0.02665  Duration: 124.605267 min
21-12-30 14:34:09.193 : ===> Valid. psnr: 24.1992, ssim: 0.8071, loss: 0.0266
21-12-30 14:34:09.365 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_8.pth
21-12-30 14:34:09.365 : 


21-12-30 16:18:21.346 : #################### Trainning Resumed ####################
21-12-30 16:18:21.346 : scale4
21-12-30 16:18:23.478 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-30 16:18:25.214 : ===>Input:[4,3,256,256] output:[4,3,1024,1024]
21-12-30 16:18:25.308 :        DEVICE ID : cuda
21-12-30 16:18:30.962 : L1 loss function
21-12-30 16:18:31.030 : ===> TrainEpoch =9  lr = 1e-05
21-12-30 18:19:10.942 : ===> Epoch[9]: Loss_l1: 0.02621  Duration: 120.672383 min
21-12-30 18:42:48.183 : ===> Valid. psnr: 24.5148, ssim: 0.8123, loss: 0.0257
21-12-30 18:42:48.275 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_9.pth
21-12-30 18:42:48.275 : 

21-12-30 20:28:53.288 : 

21-12-30 20:28:53.288 : #################### Trainning Resumed ####################
21-12-30 20:28:53.288 : scale4
21-12-30 20:29:25.890 : 

21-12-30 20:29:25.890 : #################### Trainning Resumed ####################
21-12-30 20:29:25.890 : scale4
21-12-30 20:29:26.751 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-30 20:29:30.089 : ===>Input:[4,3,256,256] output:[4,3,1024,1024]
21-12-30 20:29:30.193 :        DEVICE ID : cuda
21-12-30 20:29:36.489 : L1 loss function
21-12-30 20:29:36.562 : ===> TrainEpoch =10  lr = 1e-05
21-12-30 22:26:12.590 : ===> Epoch[10]: Loss_l1: 0.02583  Duration: 116.601367 min
21-12-30 22:47:21.087 : ===> Valid. psnr: 24.7420, ssim: 0.8163, loss: 0.0250
21-12-30 22:47:21.157 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_10.pth
21-12-30 22:47:21.157 : 

21-12-31 08:50:13.674 : 

21-12-31 08:50:13.676 : #################### Trainning Resumed ####################
21-12-31 08:50:13.676 : scale4
21-12-31 08:50:15.779 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-31 08:50:17.175 : ===>Input:[4,3,256,256] output:[4,3,1024,1024]
21-12-31 08:50:17.278 :        DEVICE ID : cuda
21-12-31 08:50:23.032 : L1 loss function
21-12-31 08:50:23.116 : ===> TrainEpoch =11  lr = 1e-05
21-12-31 12:06:52.734 : 

21-12-31 12:06:52.735 : #################### Trainning Resumed ####################
21-12-31 12:06:52.735 : scale4
21-12-31 12:06:55.660 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-31 12:06:57.386 : ===>Input:[4,3,256,256] output:[4,3,1024,1024]
21-12-31 12:06:57.472 :        DEVICE ID : cuda
21-12-31 12:07:03.729 : L1 loss function
21-12-31 12:07:03.812 : ===> TrainEpoch =11  lr = 1e-05
21-12-31 12:09:34.798 : 

21-12-31 12:09:34.798 : #################### Trainning Resumed ####################
21-12-31 12:09:34.798 : scale4
21-12-31 12:09:49.545 : 

21-12-31 12:09:49.545 : #################### Trainning Resumed ####################
21-12-31 12:09:49.545 : scale4
21-12-31 12:09:51.697 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
21-12-31 12:09:54.343 : ===>Input:[4,3,256,256] output:[4,3,1024,1024]
21-12-31 12:09:54.440 :        DEVICE ID : cuda
21-12-31 12:10:00.245 : L1 loss function
21-12-31 12:10:00.334 : ===> TrainEpoch =11  lr = 1e-05
21-12-31 14:07:32.803 : ===> Epoch[11]: Loss_l1: 0.02526  Duration: 117.551608 min
21-12-31 14:30:26.021 : ===> Valid. psnr: 24.6480, ssim: 0.8184, loss: 0.0248
21-12-31 14:30:26.128 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_11.pth
21-12-31 14:30:26.128 : 

21-12-31 14:30:26.129 : ===> TrainEpoch =12  lr = 1e-05
21-12-31 16:29:24.769 : ===> Epoch[12]: Loss_l1: 0.02502  Duration: 118.978983 min
21-12-31 16:50:28.277 : ===> Valid. psnr: 24.6998, ssim: 0.8205, loss: 0.0248
21-12-31 16:50:28.324 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_12.pth
21-12-31 16:50:28.324 : 


22-01-01 13:00:58.294 : #################### Trainning Resumed ####################
22-01-01 13:00:58.294 : scale4
22-01-01 13:01:01.091 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
22-01-01 13:01:04.998 : ===>Input:[16,3,128,128] output:[16,3,512,512]
22-01-01 13:01:05.083 :        DEVICE ID : cuda
22-01-01 13:01:13.155 : L1 loss function
22-01-01 13:01:13.284 : ===> TrainEpoch =13  lr = 1e-05
22-01-01 13:27:16.578 : ===> Epoch[13]: Loss_l1: 0.03650  Duration: 26.054637 min
22-01-01 13:31:46.676 : ===> Valid. psnr: 23.6269, ssim: 0.7431, loss: 0.0362
22-01-01 13:31:46.809 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_13.pth
22-01-01 13:31:46.809 : 

22-01-01 13:31:46.810 : ===> TrainEpoch =14  lr = 1e-05
22-01-01 13:57:47.657 : ===> Epoch[14]: Loss_l1: 0.03624  Duration: 26.015392 min
22-01-01 14:02:26.626 : ===> Valid. psnr: 23.6248, ssim: 0.7429, loss: 0.0368
22-01-01 14:02:26.722 : ===> Checkpoint saved to checkpoints/face_checkpoints/checkpoint_epoch_14.pth
22-01-01 14:02:26.722 : 

22-01-01 14:02:26.723 : ===> TrainEpoch =15  lr = 1e-05
22-01-01 15:09:48.756 : 

22-01-01 15:09:48.757 : #################### Trainning Resumed ####################
22-01-01 15:09:48.757 : scale1
22-01-01 15:09:58.093 : 

22-01-01 15:09:58.093 : #################### Trainning Resumed ####################
22-01-01 15:09:58.093 : scale1
22-01-01 15:10:00.285 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
22-01-01 15:10:05.966 : ===>Input:[16,3,256,256] output:[16,3,256,256]
22-01-01 15:10:06.060 :        DEVICE ID : cuda
22-01-01 15:10:11.832 : L1 loss function
22-01-01 15:11:21.870 : 

22-01-01 15:11:21.870 : #################### Trainning Resumed ####################
22-01-01 15:11:21.870 : scale1
22-01-01 15:11:23.559 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
22-01-01 15:11:28.232 : ===>Input:[16,3,256,256] output:[16,3,256,256]
22-01-01 15:11:28.298 :        DEVICE ID : cuda
22-01-01 15:11:31.735 : L1 loss function
22-01-01 15:12:34.739 : 

22-01-01 15:12:34.740 : #################### Trainning Resumed ####################
22-01-01 15:12:34.740 : scale1
22-01-01 15:12:34.790 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
22-01-01 15:12:39.747 : ===>Input:[16,3,256,256] output:[16,3,256,256]
22-01-01 15:12:39.808 :        DEVICE ID : cuda
22-01-01 15:12:42.590 : L1 loss function
22-01-01 15:12:42.703 : ===> TrainEpoch =13  lr = 1e-05
22-01-01 15:13:23.765 : 

22-01-01 15:13:23.765 : #################### Trainning Resumed ####################
22-01-01 15:13:23.765 : scale1
22-01-01 15:13:24.028 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:8
22-01-01 15:13:26.615 : ===>Input:[8,3,256,256] output:[8,3,256,256]
22-01-01 15:13:26.679 :        DEVICE ID : cuda
22-01-01 15:13:29.595 : L1 loss function
22-01-01 15:13:29.680 : ===> TrainEpoch =33  lr = 5e-06
22-01-01 15:13:52.517 : 

22-01-01 15:13:52.517 : #################### Trainning Resumed ####################
22-01-01 15:13:52.518 : scale1
22-01-01 15:13:52.563 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
22-01-01 15:13:54.056 : ===>Input:[4,3,256,256] output:[4,3,256,256]
22-01-01 15:13:54.111 :        DEVICE ID : cuda
22-01-01 15:13:56.914 : L1 loss function
22-01-01 15:13:56.981 : ===> TrainEpoch =33  lr = 5e-06
22-01-01 15:14:41.188 : 

22-01-01 15:14:41.188 : #################### Trainning Resumed ####################
22-01-01 15:14:41.188 : scale1
22-01-01 15:14:41.237 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
22-01-01 15:14:42.822 : ===>Input:[4,3,200,200] output:[4,3,200,200]
22-01-01 15:14:42.878 :        DEVICE ID : cuda
22-01-01 15:14:45.682 : L1 loss function
22-01-01 15:14:45.748 : ===> TrainEpoch =13  lr = 1e-05
22-01-01 15:17:45.163 : 

22-01-01 15:17:45.163 : #################### Trainning Resumed ####################
22-01-01 15:17:45.163 : scale4
22-01-01 15:17:45.213 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:26
22-01-01 15:17:54.143 : ===>Input:[26,3,256,256] output:[26,3,256,256]
22-01-01 15:17:54.215 :        DEVICE ID : cuda
22-01-01 15:17:57.109 : L1 loss function
22-01-01 15:18:17.428 : 

22-01-01 15:18:17.428 : #################### Trainning Resumed ####################
22-01-01 15:18:17.428 : scale4
22-01-01 15:18:17.639 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
22-01-01 15:18:23.887 : ===>Input:[16,3,256,256] output:[16,3,256,256]
22-01-01 15:18:23.950 :        DEVICE ID : cuda
22-01-01 15:18:26.805 : L1 loss function
22-01-01 15:18:26.844 : ===> TrainEpoch =13  lr = 1e-05
22-01-01 15:18:45.408 : 

22-01-01 15:18:45.408 : #################### Trainning Resumed ####################
22-01-01 15:18:45.408 : scale1
22-01-01 15:18:45.459 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:16
22-01-01 15:18:49.477 : ===>Input:[16,3,256,256] output:[16,3,256,256]
22-01-01 15:18:49.537 :        DEVICE ID : cuda
22-01-01 15:18:52.501 : L1 loss function
22-01-01 15:18:52.541 : ===> TrainEpoch =13  lr = 1e-05
22-01-01 15:19:09.874 : 

22-01-01 15:19:09.874 : #################### Trainning Resumed ####################
22-01-01 15:19:09.874 : scale1
22-01-01 15:19:09.928 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:8
22-01-01 15:19:12.167 : ===>Input:[8,3,256,256] output:[8,3,256,256]
22-01-01 15:19:12.225 :        DEVICE ID : cuda
22-01-01 15:19:14.969 : L1 loss function
22-01-01 15:19:15.006 : ===> TrainEpoch =13  lr = 1e-05
22-01-01 15:20:01.194 : 

22-01-01 15:20:01.195 : #################### Trainning Resumed ####################
22-01-01 15:20:01.195 : scale1
22-01-01 15:20:01.272 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:8
22-01-01 15:20:03.985 : ===>Input:[8,3,256,256] output:[8,3,256,256]
22-01-01 15:20:04.041 :        DEVICE ID : cuda
22-01-01 15:20:06.750 : L1 loss function
22-01-01 15:20:06.788 : ===> TrainEpoch =0  lr = 1e-05
22-01-02 10:27:13.742 : 

22-01-02 10:27:13.742 : #################### Trainning Resumed ####################
22-01-02 10:27:13.742 : scale4
22-01-02 10:27:24.581 : 

22-01-02 10:27:24.581 : #################### Trainning Resumed ####################
22-01-02 10:27:24.581 : scale4
22-01-02 10:27:26.552 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
22-01-02 10:27:29.137 : ===>Input:[4,3,256,256] output:[4,3,256,256]
22-01-02 10:27:29.231 :        DEVICE ID : cuda
22-01-02 10:27:35.615 : L1 loss function
22-01-02 10:27:35.619 : ===> TrainEpoch =0  lr = 1e-05
22-01-02 10:29:18.006 : 

22-01-02 10:29:18.006 : #################### Trainning Resumed ####################
22-01-02 10:29:18.006 : scale4
22-01-02 10:29:19.830 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
22-01-02 10:29:23.521 : ===>Input:[4,3,256,256] output:[4,3,256,256]
22-01-02 10:29:23.581 :        DEVICE ID : cuda
22-01-02 10:29:26.567 : L1 loss function
22-01-02 10:29:26.568 : ===> TrainEpoch =0  lr = 1e-05
22-01-02 10:30:40.219 : 

22-01-02 10:30:40.219 : #################### Trainning Resumed ####################
22-01-02 10:30:40.219 : scale4
22-01-02 10:30:40.433 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:4
22-01-02 10:30:44.627 : ===>Input:[4,3,512,512] output:[4,3,512,512]
22-01-02 10:30:44.679 :        DEVICE ID : cuda
22-01-02 10:30:47.503 : L1 loss function
22-01-02 10:30:47.505 : ===> TrainEpoch =0  lr = 1e-05
22-01-02 10:32:23.426 : 

22-01-02 10:32:23.426 : #################### Trainning Resumed ####################
22-01-02 10:32:23.426 : scale1
22-01-02 10:32:23.771 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:8
22-01-02 10:32:29.624 : ===>Input:[8,3,512,512] output:[8,3,512,512]
22-01-02 10:32:29.683 :        DEVICE ID : cuda
22-01-02 10:32:32.425 : L1 loss function
22-01-02 10:32:32.426 : ===> TrainEpoch =0  lr = 1e-05
22-01-02 10:33:16.474 : 

22-01-02 10:33:16.474 : #################### Trainning Resumed ####################
22-01-02 10:33:16.475 : scale1
22-01-02 10:33:16.542 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:8
22-01-02 10:33:22.835 : ===>Input:[8,3,480,480] output:[8,3,480,480]
22-01-02 10:33:22.892 :        DEVICE ID : cuda
22-01-02 10:33:25.699 : L1 loss function
22-01-02 10:33:25.700 : ===> TrainEpoch =0  lr = 1e-05
22-01-02 10:33:55.522 : 

22-01-02 10:33:55.522 : #################### Trainning Resumed ####################
22-01-02 10:33:55.522 : scale1
22-01-02 10:33:55.716 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:8
22-01-02 10:34:00.499 : ===>Input:[8,3,470,470] output:[8,3,470,470]
22-01-02 10:34:00.556 :        DEVICE ID : cuda
22-01-02 10:34:03.399 : L1 loss function
22-01-02 10:34:03.401 : ===> TrainEpoch =0  lr = 1e-05
22-01-02 10:34:33.615 : 

22-01-02 10:34:33.615 : #################### Trainning Resumed ####################
22-01-02 10:34:33.615 : scale1
22-01-02 10:34:33.716 : ===>Trainning Data:[ Train:9143  Valid:1000] Batch:8
22-01-02 10:34:39.092 : ===>Input:[8,3,420,420] output:[8,3,420,420]
22-01-02 10:34:39.147 :        DEVICE ID : cuda
22-01-02 10:34:41.934 : L1 loss function
22-01-02 10:34:41.936 : ===> TrainEpoch =0  lr = 1e-05
